{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autots.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1NPBAmdZmk4Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autots"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWBDeutzmnfM",
        "outputId": "aafed96e-d004-4554-fb21-296fe924f721"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autots in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from autots) (1.21.6)\n",
            "Requirement already satisfied: statsmodels>=0.10.* in /usr/local/lib/python3.7/dist-packages (from autots) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.25.* in /usr/local/lib/python3.7/dist-packages (from autots) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.*->autots) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.*->autots) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.*->autots) (1.7.3)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.10.*->autots) (0.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autots import AutoTS"
      ],
      "metadata": {
        "id": "jjmE0TeYm0xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1883b60d-9659-469c-8ed5-9e683ebb1ce1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "XhaTjlZaZhb3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "# data = pd.read_excel(io.BytesIO(uploaded['Maindata.xlsx']))\n",
        "data = pd.read_excel(\"Maindata.xlsx\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "9_vD71YoC2H4",
        "outputId": "57232fc3-08c1-497c-9416-7f6425688087"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Zone Dealer Code Dealer Name  Transaction No. Description Status  \\\n",
              "0  NaN         NaN         NaN       2000095635      Medium   Open   \n",
              "1  NaN         NaN         NaN       1000003085   Very High   Open   \n",
              "2  NaN         NaN         NaN       1000003086      Medium   Open   \n",
              "3  NaN         NaN         NaN       2000095644   Very High   Open   \n",
              "4  NaN         NaN         NaN       2000095646        High   Open   \n",
              "\n",
              "  Posting Date  IRT     CATEGORY IRTSTATUS  MPT MPTSTATUS Changed On  \\\n",
              "0   2022-05-06    0        Sales       NaN    0       NaN 2022-05-06   \n",
              "1   2022-05-06    0          NaN       NaN    0       NaN 2022-05-06   \n",
              "2   2022-05-06    0          NaN       NaN    0       NaN 2022-05-06   \n",
              "3   2022-05-06    0  After Sales       NaN    0       NaN 2022-05-06   \n",
              "4   2022-05-06    0        Sales       NaN    0       NaN 2022-05-06   \n",
              "\n",
              "      TRANSACTIONTYPE   Created By Reported By  Object GUID  \n",
              "0  MG_MOTORS_Incident  ANANDSHARMA         NaN            0  \n",
              "1    MG Parts Support  S309PRM0001         NaN            0  \n",
              "2    MG Parts Support  WW14PRM0001         NaN            0  \n",
              "3  MG_MOTORS_Incident  DW02HSR0001         NaN            0  \n",
              "4  MG_MOTORS_Incident  DE04CRE0001         NaN            0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a1c1dca-1078-475c-91d4-3d28aefd76af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Zone</th>\n",
              "      <th>Dealer Code</th>\n",
              "      <th>Dealer Name</th>\n",
              "      <th>Transaction No.</th>\n",
              "      <th>Description</th>\n",
              "      <th>Status</th>\n",
              "      <th>Posting Date</th>\n",
              "      <th>IRT</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>IRTSTATUS</th>\n",
              "      <th>MPT</th>\n",
              "      <th>MPTSTATUS</th>\n",
              "      <th>Changed On</th>\n",
              "      <th>TRANSACTIONTYPE</th>\n",
              "      <th>Created By</th>\n",
              "      <th>Reported By</th>\n",
              "      <th>Object GUID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000095635</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Open</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>MG_MOTORS_Incident</td>\n",
              "      <td>ANANDSHARMA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000003085</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Open</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>MG Parts Support</td>\n",
              "      <td>S309PRM0001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000003086</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Open</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>MG Parts Support</td>\n",
              "      <td>WW14PRM0001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000095644</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Open</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>0</td>\n",
              "      <td>After Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>MG_MOTORS_Incident</td>\n",
              "      <td>DW02HSR0001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000095646</td>\n",
              "      <td>High</td>\n",
              "      <td>Open</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-05-06</td>\n",
              "      <td>MG_MOTORS_Incident</td>\n",
              "      <td>DE04CRE0001</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a1c1dca-1078-475c-91d4-3d28aefd76af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a1c1dca-1078-475c-91d4-3d28aefd76af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a1c1dca-1078-475c-91d4-3d28aefd76af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"IRTSTATUS\",\"MPTSTATUS\",\"Object GUID\"],axis=1,inplace=True)\n",
        "data.columns=[\"zone\",\"dealer_code\",\"dealer_name\",\"trans_no.\",\"description\",\"status\",\"posting_date\",\"IRT\",\"category\",\"MPT\",\"changed_on\",\"transaction_type\",\"created_by\",\"reported_by\"]"
      ],
      "metadata": {
        "id": "DMaIcmu8DKZ1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_tickets = data.groupby([\"posting_date\"]).agg({\"description\":\"count\"})\n",
        "date_tickets.reset_index(inplace=True)\n",
        "date_tickets.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9kJ3KEinDMpj",
        "outputId": "9865e7a4-b47b-4582-9ff2-d981841a98ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  posting_date  description\n",
              "0   2020-02-27            1\n",
              "1   2020-02-28           14\n",
              "2   2020-02-29            4\n",
              "3   2020-03-02            1\n",
              "4   2020-03-03            2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f61d667-106f-4199-bf32-d912bc66c999\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_date</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-02-27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f61d667-106f-4199-bf32-d912bc66c999')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f61d667-106f-4199-bf32-d912bc66c999 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f61d667-106f-4199-bf32-d912bc66c999');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_tickets[\"posting_date\"]=pd.to_datetime(date_tickets[\"posting_date\"])\n",
        "date_tickets.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxjjBHwtDNTF",
        "outputId": "ed56b7b3-805c-4fc4-df89-c87a724b39d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 794 entries, 0 to 793\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   posting_date  794 non-null    datetime64[ns]\n",
            " 1   description   794 non-null    int64         \n",
            "dtypes: datetime64[ns](1), int64(1)\n",
            "memory usage: 12.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_tickets.description.max()"
      ],
      "metadata": {
        "id": "krW2DjgOfUEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da21155-d9bf-46e1-a5c1-ff525689a9f8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "321"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = AutoTS(forecast_length=20, frequency='infer',  ensemble='simple')"
      ],
      "metadata": {
        "id": "XgukQw3Fj5Nu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = date_tickets.iloc[:670]\n",
        "test = date_tickets.iloc[670:]\n",
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njXnFv-FeH4t",
        "outputId": "08b03e6f-a372-4d44-bb40-716820149ec6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 670 entries, 0 to 669\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   posting_date  670 non-null    datetime64[ns]\n",
            " 1   description   670 non-null    int64         \n",
            "dtypes: datetime64[ns](1), int64(1)\n",
            "memory usage: 10.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = mod.fit(train, date_col='posting_date', value_col='description', id_col=None)\n",
        "print(mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJTA-D8tkKfa",
        "outputId": "bfb04342-6e45-490a-fdf7-7eb572b64eaa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: D\n",
            "Model Number: 1 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 7s 7ms/step - loss: 0.3862\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3577\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3296\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3259\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3177\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3129\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3098\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3078\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3080\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3029\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3010\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2966\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2930\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2906\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2850\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2814\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2826\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2814\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2785\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2743\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2706\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2664\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2608\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2600\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2591\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2568\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2554\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2554\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2517\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2515\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2483\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2480\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2471\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2460\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2467\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2530\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2467\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2417\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2443\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2577\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2378\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2419\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2443\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.2465\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2373\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2384\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2350\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2386\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2388\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2387\n",
            "Model Number: 8 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 10 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 10: GLM\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLS in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n",
            "Model Number: 14 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 14: GluonTS\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 15: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 16: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
            "Model Number: 19 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 26: UnobservedComponents\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 29: VAR\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30: VAR\n",
            "Model Number: 31 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 31: VECM\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32: VECM\n",
            "Model Number: 33 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 34 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 35 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 36 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 36: GluonTS\n",
            "Model Number: 37 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 38: MultivariateRegression\n",
            "Model Number: 39 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 39: DatepartRegression\n",
            "Model Number: 40 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 41 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 42 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 42: UnobservedComponents\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 43: UnobservedComponents\n",
            "Model Number: 44 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 45 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 45: VECM\n",
            "Model Number: 46 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 46: ARDL\n",
            "Model Number: 47 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 49 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 53 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 54 with model FBProphet in generation 0 of 10\n",
            "Model Number: 55 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 56 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 57 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 58 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 58: Theta\n",
            "Model Number: 59 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 60 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 61 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 62 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 63 with model GLS in generation 0 of 10\n",
            "Model Number: 64 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 65: GLM\n",
            "Model Number: 66 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 67 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 68 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 68: GluonTS\n",
            "Model Number: 69 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 70 with model VAR in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 70: VAR\n",
            "Model Number: 71 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 71: VECM\n",
            "Model Number: 72 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 72: WindowRegression\n",
            "Model Number: 73 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 73: DatepartRegression\n",
            "Model Number: 74 with model UnivariateRegression in generation 0 of 10\n",
            "Model Number: 75 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 75: MultivariateRegression\n",
            "Model Number: 76 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 77 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 78 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 79 with model NVAR in generation 0 of 10\n",
            "Model Number: 80 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 80: Theta\n",
            "Model Number: 81 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/api.py)\") in model 81: ARDL\n",
            "Model Number: 82 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 82: VAR\n",
            "Model Number: 83 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 84 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 84: GLM\n",
            "Model Number: 85 with model NVAR in generation 0 of 10\n",
            "Model Number: 86 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 87 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 88 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 89 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 90 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 91 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 91: GLM\n",
            "Model Number: 92 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 93 with model GLM in generation 0 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 93: GLM\n",
            "Model Number: 94 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 95 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 95: LastValueNaive\n",
            "Model Number: 96 with model GLS in generation 0 of 10\n",
            "Model Number: 97 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 97: UnobservedComponents\n",
            "Model Number: 98 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 100 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 101 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 101: ConstantNaive\n",
            "Model Number: 102 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 102: VAR\n",
            "Model Number: 103 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 104 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 105 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 106 with model MultivariateMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 106: MultivariateMotif\n",
            "Model Number: 107 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 108 with model WindowRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:48: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 109 with model Theta in generation 0 of 10\n",
            "Template Eval Error: ModuleNotFoundError(\"No module named 'statsmodels.tsa.forecasting'\") in model 109: Theta\n",
            "Model Number: 110 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 111 with model NVAR in generation 0 of 10\n",
            "Model Number: 112 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 113 with model FBProphet in generation 0 of 10\n",
            "Model Number: 114 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 115 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 13ms/step - loss: 122.9638\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 108.4737\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.4245\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 109.3122\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 106.7179\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106.9522\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.5669\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.2148\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.9455\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.5480\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 110.0577\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.5255\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.9079\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 106.4538\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.4186\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.6935\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.4458\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.8772\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.1158\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.2964\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 104.7006\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.5655\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.4053\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.1648\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.4751\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.0536\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.9034\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.6340\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.4712\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.5309\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.0917\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9093\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.5429\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.2996\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.3728\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.6379\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.2505\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.3256\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.2111\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.6911\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.5298\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.7969\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.0761\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.4227\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.2268\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.0236\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.4593\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.4324\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 103.2954\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 99.9347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 116 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 117 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 118 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 119 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 120 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 121 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 122 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 123 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 123: VAR\n",
            "Model Number: 124 with model GLS in generation 0 of 10\n",
            "Model Number: 125 with model WindowRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 7s 5ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: nan\n",
            "Model Number: 126 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 127 with model WindowRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 127: WindowRegression\n",
            "Model Number: 128 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 129 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 130 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 130: ARDL\n",
            "Model Number: 131 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 132 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 133 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 133: UnobservedComponents\n",
            "Model Number: 134 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 135 with model NVAR in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 136 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 137 with model NVAR in generation 0 of 10\n",
            "Model Number: 138 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 139 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 140 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 141 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 142 with model ETS in generation 0 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on description with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 143 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 143: ARDL\n",
            "Model Number: 144 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 145 with model NVAR in generation 0 of 10\n",
            "Model Number: 146 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 146: VAR\n",
            "Model Number: 147 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 148 with model GLS in generation 0 of 10\n",
            "Model Number: 149 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 150 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 151 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 152 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 153 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 154 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 155 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 155: GluonTS\n",
            "Model Number: 156 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 156: VAR\n",
            "Model Number: 157 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 158 with model GLS in generation 0 of 10\n",
            "Model Number: 159 with model GLM in generation 0 of 10\n",
            "Model Number: 160 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 161 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 162 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 162: VAR\n",
            "Model Number: 163 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 164 with model NVAR in generation 0 of 10\n",
            "Model Number: 165 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 165: GluonTS\n",
            "Model Number: 166 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 167 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 167: ARDL\n",
            "Model Number: 168 with model SectionalMotif in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 168: SectionalMotif\n",
            "Model Number: 169 with model AverageValueNaive in generation 0 of 10\n",
            "New Generation: 1 of 10\n",
            "Model Number: 170 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 170: DatepartRegression\n",
            "Model Number: 171 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 172 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 173 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 174 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 174: UnobservedComponents\n",
            "Model Number: 175 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 176 with model NVAR in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 177 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 178 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 179 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 180 with model GLS in generation 1 of 10\n",
            "Model Number: 181 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 182 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 183 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 184 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 185 with model SeasonalNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 186 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 187 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 187: UnobservedComponents\n",
            "Model Number: 188 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 189 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 190 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 191 with model GLS in generation 1 of 10\n",
            "Model Number: 192 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 193 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 194 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 195 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 196 with model LastValueNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 197 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 198 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 6s 7ms/step - loss: 0.0794\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0769\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0756\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0754\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0740\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0734\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0717\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0707\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0700\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0696\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0693\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0679\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0665\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0655\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0647\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0633\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0620\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0625\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0619\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0614\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0603\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0590\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0593\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0604\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0593\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0578\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0595\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0596\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0571\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0590\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0567\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0561\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0573\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0565\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0579\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0563\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0556\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0555\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0565\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0572\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0545\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0555\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0539\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0558\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0554\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0542\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0534\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0556\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0539\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0553\n",
            "Model Number: 199 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 200 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 201 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 202 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 203 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 14ms/step - loss: 144.9549\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 126.3554\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 124.8418\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 122.1462\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 128.7733\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 121.3541\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 118.2291\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 114.8626\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 113.3629\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 119.2763\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.6204\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 107.6242\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106.7717\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 109.5100\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 110.8364\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.5833\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.1383\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106.6945\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 110.3394\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.2971\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.4257\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.0721\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.0749\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 109.7119\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.9620\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 108.4357\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 105.6126\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.8293\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.2583\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 104.2981\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.0698\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.4131\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.8432\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.7521\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1640\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.2949\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.7627\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.3315\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.3677\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.6415\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.2765\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.3382\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.5292\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.2468\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.2754\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.2889\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.8497\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.5638\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.4862\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.7009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9f6c3707a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 204 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 205 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 206 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 207 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 208 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 209 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 210 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 211 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 212 with model GLS in generation 1 of 10\n",
            "Model Number: 213 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 213: DatepartRegression\n",
            "Model Number: 214 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 215 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 216 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 217 with model NVAR in generation 1 of 10\n",
            "Model Number: 218 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 219 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 220 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 221 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 222 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 223 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 223: DatepartRegression\n",
            "Model Number: 224 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 224: MultivariateRegression\n",
            "Model Number: 225 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 226 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 227 with model GLS in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 228 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 229 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 230 with model NVAR in generation 1 of 10\n",
            "Model Number: 231 with model GLS in generation 1 of 10\n",
            "Model Number: 232 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 233 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 234 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 235 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 236 with model SeasonalNaive in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 237 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 238 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 239 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 240 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 241 with model NVAR in generation 1 of 10\n",
            "Model Number: 242 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 243 with model ConstantNaive in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 243: ConstantNaive\n",
            "Model Number: 244 with model UnobservedComponents in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 244: UnobservedComponents\n",
            "Model Number: 245 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 245: MultivariateRegression\n",
            "Model Number: 246 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 247 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 248 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 249 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 250 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 251 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 252 with model WindowRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 252: WindowRegression\n",
            "Model Number: 253 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 254 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 255 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 256 with model GLS in generation 1 of 10\n",
            "Model Number: 257 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 258 with model WindowRegression in generation 1 of 10\n",
            "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 258: WindowRegression\n",
            "Model Number: 259 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 260 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 261 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 262 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 262: MultivariateRegression\n",
            "Model Number: 263 with model NVAR in generation 1 of 10\n",
            "Model Number: 264 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 265 with model NVAR in generation 1 of 10\n",
            "Model Number: 266 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 267 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 268 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 269 with model UnivariateRegression in generation 1 of 10\n",
            "Model Number: 270 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 271 with model NVAR in generation 1 of 10\n",
            "Model Number: 272 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 272: MultivariateRegression\n",
            "Model Number: 273 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 274 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 275 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 276 with model WindowRegression in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 277 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 278 with model ETS in generation 1 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 279 with model ConstantNaive in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 280 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 281 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 282 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 283 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 284 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 285 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 286 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 287 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 288 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 288: DatepartRegression\n",
            "Model Number: 289 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 7s 7ms/step - loss: 0.0874\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0413\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0386\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0364\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0340\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0324\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0332\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0325\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0323\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0316\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0308\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0305\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0300\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0303\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0289\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0284\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0280\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0284\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0281\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0281\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0282\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0281\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0271\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0278\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0268\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0273\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0268\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0276\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0263\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0270\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0263\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0255\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0265\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0261\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0270\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0261\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0263\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0254\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0253\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0266\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0250\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0257\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0256\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0254\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0245\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0247\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0243\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0248\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0250\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9f6c370200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 290 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 291 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 292 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 293 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 294 with model FBProphet in generation 2 of 10\n",
            "Model Number: 295 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 296 with model AverageValueNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 297 with model FBProphet in generation 2 of 10\n",
            "Model Number: 298 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 299 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 300 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 301 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 302 with model NVAR in generation 2 of 10\n",
            "Model Number: 303 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 304 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 305 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 306 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 307 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 308 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 309 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 310 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 311 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 312 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 313 with model GLS in generation 2 of 10\n",
            "Model Number: 314 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 315 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 316 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 317 with model NVAR in generation 2 of 10\n",
            "Model Number: 318 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 319 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 320 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 321 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 322 with model NVAR in generation 2 of 10\n",
            "Model Number: 323 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 324 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 325 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 326 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 327 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 328 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 329 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 330 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 331 with model GLS in generation 2 of 10\n",
            "Model Number: 332 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 333 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 334 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 335 with model GLS in generation 2 of 10\n",
            "Model Number: 336 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 337 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 338 with model FBProphet in generation 2 of 10\n",
            "Model Number: 339 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 340 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 341 with model GLS in generation 2 of 10\n",
            "Model Number: 342 with model DatepartRegression in generation 2 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 11ms/step - loss: 136.1797\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 137.1020\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 120.9439\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 112.6416\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 119.5931\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 116.9084\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 112.9883\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 115.2109\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 112.9824\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 114.1308\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 106.4413\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 107.3796\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 108.9989\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.9339\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 109.6551\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 111.2835\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.6189\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.9729\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 106.6163\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 108.1870\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.0401\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.6594\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.8539\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1361\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 104.4315\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.7167\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.5573\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.1340\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.2809\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.5820\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.3281\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.2846\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.0872\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.2441\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.3277\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.7387\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.5013\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.4383\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1738\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.2650\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.5907\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.5397\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.8165\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.9433\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.2985\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.7725\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.6253\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.2122\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.4818\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.3028\n",
            "Model Number: 343 with model NVAR in generation 2 of 10\n",
            "Model Number: 344 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 345 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 346 with model GLS in generation 2 of 10\n",
            "Model Number: 347 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 348 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 349 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 350 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 350: UnobservedComponents\n",
            "Model Number: 351 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 351: ETS\n",
            "Model Number: 352 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 353 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 354 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 355 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 356 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 357 with model NVAR in generation 2 of 10\n",
            "Model Number: 358 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 358: DatepartRegression\n",
            "Model Number: 359 with model NVAR in generation 2 of 10\n",
            "Model Number: 360 with model WindowRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 360: WindowRegression\n",
            "Model Number: 361 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 362 with model WindowRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 363 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 364 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 365 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 366 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 367 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 368 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 369 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 370 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 371 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 372 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 373 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 374 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 375 with model NVAR in generation 2 of 10\n",
            "Model Number: 376 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 377 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 378 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 379 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 380 with model NVAR in generation 2 of 10\n",
            "Model Number: 381 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 382 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 383 with model UnobservedComponents in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 384 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 385 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 386 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 387 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 388 with model ETS in generation 2 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 389 with model NVAR in generation 2 of 10\n",
            "New Generation: 3 of 10\n",
            "Model Number: 390 with model UnobservedComponents in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 391 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 392 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 393 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 394 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 395 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 396 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on description with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 397 with model NVAR in generation 3 of 10\n",
            "Model Number: 398 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 399 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 400 with model NVAR in generation 3 of 10\n",
            "Model Number: 401 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 402 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 403 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 404 with model MultivariateRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 405 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 406 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 234246.3594\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 182892.6406\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 208000.5625\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 193990.8438\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 121325.4062\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 205633.9531\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 85022.9531\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 144766.7969\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 155977.1562\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 56965.4023\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 83630.2188\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 129898.9297\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 71988.0781\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 111067.1797\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 155212.2969\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 74172.5469\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 60311.0898\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 68535.5391\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 253279.5312\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 52058.1172\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 42231.3242\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 60762.1172\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 80068.8516\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 33772.1406\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100097.9609\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 81450.6484\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 51653.6719\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 54627.6055\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 35275.5820\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 77669.6484\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 32949.9805\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 66561.9844\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 65708.7500\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 48604.8789\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 40935.2305\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 59947.2266\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 35789.4062\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 53360.6953\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 23479.5625\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 47252.8281\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 55821.3477\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 25999.9238\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 42423.2031\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 20114.5918\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 28056.5762\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 35011.3828\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 28433.8652\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 40504.9297\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 31153.1621\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 33479.3555\n",
            "Model Number: 407 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 408 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 409 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 15ms/step - loss: 70640.3203\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 53036.5078\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 108949.6250\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 54794.5742\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 87878.0938\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 40481.0039\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 23097.0723\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 118313.7656\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 41007.2344\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 64701.4883\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21370.6230\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 69801.9609\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 18666.3633\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 68939.2812\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 32334.6973\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 108333.9766\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 14397.4912\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 91073.0156\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 34021.1211\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 66387.9062\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 22042.3379\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 45673.0078\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 43454.3594\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 28281.9727\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13265.8389\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103994.7578\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6947.0991\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 48462.0430\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 28527.0098\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 32827.9688\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 25222.9453\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 52470.1328\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 18977.4531\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 58213.2695\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 5973.0513\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 69375.5938\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1946.2701\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 46302.2539\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 21089.9199\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 30674.4688\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 417.5284\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 57183.6875\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 4928.8643\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 53405.7578\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 6780.1494\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 60760.9570\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 24527.4023\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 46339.7695\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12033.2764\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 46280.8945\n",
            "Model Number: 410 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 411 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 412 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 413 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 414 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 415 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 416 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 417 with model UnivariateMotif in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 417: UnivariateMotif\n",
            "Model Number: 418 with model NVAR in generation 3 of 10\n",
            "Model Number: 419 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 420 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 421 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 422 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 423 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 424 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 425 with model DatepartRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 3s 29ms/step - loss: 46798135296.0000 - val_loss: 12038349824.0000\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 13724978176.0000 - val_loss: 2679336448.0000\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 11101500416.0000 - val_loss: 1200626816.0000\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 11594489856.0000 - val_loss: 5500736512.0000\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 13030836224.0000 - val_loss: 2100574720.0000\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10378656768.0000 - val_loss: 686076864.0000\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9136013312.0000 - val_loss: 3631247104.0000\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8881960960.0000 - val_loss: 741491904.0000\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9928985600.0000 - val_loss: 3079661824.0000\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 20795523072.0000 - val_loss: 4422385152.0000\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 5423725568.0000 - val_loss: 1576975488.0000\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 5653524480.0000 - val_loss: 6469866496.0000\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6884678144.0000 - val_loss: 649696064.0000\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10541920256.0000 - val_loss: 570403136.0000\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 12224488448.0000 - val_loss: 1002136128.0000\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 12302825472.0000 - val_loss: 1506799872.0000\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7194131456.0000 - val_loss: 2033784960.0000\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7788068864.0000 - val_loss: 6431276544.0000\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 4969944576.0000 - val_loss: 2472112896.0000\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 12216592384.0000 - val_loss: 2226898176.0000\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10705335296.0000 - val_loss: 6381314048.0000\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 11866470400.0000 - val_loss: 546218816.0000\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7420986880.0000 - val_loss: 843633664.0000\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 10855667712.0000 - val_loss: 5582068224.0000\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 9895034880.0000 - val_loss: 10175354880.0000\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 5270769664.0000 - val_loss: 2905014528.0000\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 9606225920.0000 - val_loss: 1802074880.0000\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 11841178624.0000 - val_loss: 1655172224.0000\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 7012142592.0000 - val_loss: 2417594112.0000\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 8982473728.0000 - val_loss: 1743288320.0000\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 7396248064.0000 - val_loss: 936408704.0000\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 5174240768.0000 - val_loss: 4566235136.0000\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 425: DatepartRegression\n",
            "Model Number: 426 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 427 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 428 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 429 with model UnivariateMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 430 with model GLS in generation 3 of 10\n",
            "Model Number: 431 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 432 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 433 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 434 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 435 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 435: FBProphet\n",
            "Model Number: 436 with model NVAR in generation 3 of 10\n",
            "Model Number: 437 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 437: DatepartRegression\n",
            "Model Number: 438 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 439 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 440 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 441 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 442 with model FBProphet in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 442: FBProphet\n",
            "Model Number: 443 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 444 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 445 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 446 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 447 with model NVAR in generation 3 of 10\n",
            "Model Number: 448 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 449 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 450 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 451 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 11ms/step - loss: 33090.3828\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 121096.2344\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 22454.0938\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 85270.2891\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 38189.5586\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 56352.7070\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 7069.6211\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 120830.1250\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106932.1328\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 60785.6875\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 49533.7969\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 11059.5361\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 71266.6562\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 70280.0938\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 9936.3643\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 16201.7695\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 61226.0195\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2511.6494\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 66793.5703\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 12259.7285\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 57336.3828\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 20180.7363\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 62729.7383\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2796.2896\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 30388.5332\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 6746.7925\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 79586.8828\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 9263.4600\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 22133.9062\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1532.7971\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 50573.4922\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 16609.3340\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 56556.2070\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 3950.1602\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 55888.5859\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 5104.6260\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 38604.1992\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 25259.9141\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 38003.1094\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 785.3345\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 59354.3164\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3223.3416\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 17485.1953\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 5454.4609\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 25279.4277\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 24932.2637\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 25117.2324\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 17985.8457\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 24400.9082\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 21237.2559\n",
            "Model Number: 452 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 453 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 454 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "21/21 [==============================] - 7s 7ms/step - loss: 0.4443\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.4077\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3624\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3501\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3390\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3331\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3287\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.3255\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3254\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.3205\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3157\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.3108\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.3073\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3066\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2993\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2950\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2981\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2971\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2935\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2873\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2830\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2806\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2724\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.2698\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2671\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2631\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2652\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2621\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2575\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2613\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2535\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2516\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2575\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2506\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2566\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2486\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2454\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2441\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2474\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2601\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2379\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2425\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2491\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2457\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2405\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2397\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2339\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.2354\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.2377\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.2383\n",
            "Model Number: 455 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 456 with model GLS in generation 3 of 10\n",
            "Model Number: 457 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:17: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  \"Since version 1.0, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 458 with model NVAR in generation 3 of 10\n",
            "Model Number: 459 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 460 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 461 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 462 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 463 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 464 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 465 with model NVAR in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 465: NVAR\n",
            "Model Number: 466 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 467 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 468 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 469 with model AverageValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 470 with model GLS in generation 3 of 10\n",
            "Model Number: 471 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 472 with model DatepartRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 473 with model MultivariateMotif in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 474 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 475 with model GLS in generation 3 of 10\n",
            "Model Number: 476 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 477 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 478 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 479 with model GLS in generation 3 of 10\n",
            "Model Number: 480 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 481 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 482 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 483 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 484 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 485 with model GLS in generation 3 of 10\n",
            "Model Number: 486 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 11ms/step - loss: 122.5515\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 109.1642\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 104.3018\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 104.5507\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 102.5670\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.2207\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.9432\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 108.7180\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.6182\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4307\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.3984\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.2595\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.3843\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.0179\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1651\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.3622\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.5145\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7862\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.3626\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.5846\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.2708\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9388\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.5404\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.7960\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.9470\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.5050\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.9009\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.0832\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.7534\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.5936\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.2203\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.5655\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8926\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.7859\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.3477\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.2837\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.8617\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.5884\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.7905\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.7576\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8167\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.2617\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.3143\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8422\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.3772\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.2818\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.5043\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 99.3181\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.4089\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.7961\n",
            "Model Number: 487 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 488 with model MultivariateRegression in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 488: MultivariateRegression\n",
            "Model Number: 489 with model NVAR in generation 3 of 10\n",
            "Model Number: 490 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 491 with model ETS in generation 3 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 492 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 493 with model LastValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.7/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 494 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 495 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 15ms/step - loss: 1565.1781\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 572.7408\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 836.6873\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 288.7118\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 364.5444\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 501.8046\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 434.4185\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 280.5303\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 385.2450\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 316.1264\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 580.1948\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 387.7852\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 415.4937\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 249.4457\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 454.5909\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 397.2421\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 282.6043\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 354.5963\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 328.3662\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 196.6893\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 508.1495\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 195.7988\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 268.2310\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 220.9466\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 344.3890\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 248.7887\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 295.2419\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 234.7143\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 206.1926\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 224.1506\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 146.3942\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 257.5482\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 186.3470\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 221.3585\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 179.4339\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 195.8486\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 199.9493\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 172.5646\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 157.8945\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 454.8134\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 196.1050\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 193.2100\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 164.4564\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 157.6495\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 165.1822\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 235.5868\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 171.3388\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 146.9491\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 246.8510\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 285.4145\n",
            "Model Number: 496 with model GLS in generation 3 of 10\n",
            "Model Number: 497 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e+05, tolerance: 3.349e+02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 498 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 499 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 4 of 10\n",
            "Model Number: 500 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 501 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 502 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 503 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 503: DatepartRegression\n",
            "Model Number: 504 with model NVAR in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 504: NVAR\n",
            "Model Number: 505 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 506 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 507 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 508 with model FBProphet in generation 4 of 10\n",
            "Model Number: 509 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 510 with model LastValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 511 with model FBProphet in generation 4 of 10\n",
            "Model Number: 512 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 513 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 514 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 515 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 516 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 517 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 518 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 519 with model GLS in generation 4 of 10\n",
            "Model Number: 520 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.364e+05, tolerance: 3.343e+02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 521 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 522 with model GLS in generation 4 of 10\n",
            "Model Number: 523 with model MultivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 524 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 525 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 526 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 527 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 528 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 529 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 530 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 531 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 532 with model NVAR in generation 4 of 10\n",
            "Model Number: 533 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 534 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 535 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 536 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 537 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 538 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 539 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 540 with model NVAR in generation 4 of 10\n",
            "Model Number: 541 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 542 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 543 with model SectionalMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 544 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 544: UnobservedComponents\n",
            "Model Number: 545 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 545: MultivariateRegression\n",
            "Model Number: 546 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 547 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 548 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 549 with model LastValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 549: LastValueNaive\n",
            "Model Number: 550 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 551 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 552 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 553 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 554 with model MultivariateMotif in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 554: MultivariateMotif\n",
            "Model Number: 555 with model GLS in generation 4 of 10\n",
            "Model Number: 556 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 557 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 558 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 559 with model SectionalMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 560 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 560: DatepartRegression\n",
            "Model Number: 561 with model FBProphet in generation 4 of 10\n",
            "Model Number: 562 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 563 with model UnivariateRegression in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 563: UnivariateRegression\n",
            "Model Number: 564 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 565 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 566 with model GLS in generation 4 of 10\n",
            "Model Number: 567 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 568 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 569 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 570 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 571 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 12ms/step - loss: 137985.8906\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 35505.1680\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 109453.7578\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 30265.0547\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 88809.3906\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10438.6680\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 57676.3164\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 9253.5645\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 104455.8516\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 11189.1172\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 64386.8906\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 23283.3887\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 28462.8574\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 24203.4414\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 45167.1680\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 7671.7065\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 69770.5391\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 45791.3945\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 91737.9297\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 43127.5625\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 23647.9648\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 40922.9531\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 38850.3398\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 11031.2285\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 46476.8125\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12350.4346\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 44302.5352\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 13563.2227\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 54482.7031\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2319.6614\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 60711.3164\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1566.7850\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 34485.9219\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 13943.7314\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 40333.0195\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 8676.4570\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 57009.6406\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12511.7549\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 37974.0195\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 149.1175\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 36542.4062\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 12302.4697\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 47951.0781\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 6573.2485\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 23061.8340\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1457.8088\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 32177.5059\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 14853.9893\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 26028.2559\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10504.5566\n",
            "Model Number: 572 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 573 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 574 with model WindowRegression in generation 4 of 10\n",
            "Model Number: 575 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 576 with model NVAR in generation 4 of 10\n",
            "Model Number: 577 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 578 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-2)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 579 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 580 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 581 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 582 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 583 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 584 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 585 with model UnobservedComponents in generation 4 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 585: UnobservedComponents\n",
            "Model Number: 586 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 587 with model ETS in generation 4 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 588 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 589 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 590 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 590: DatepartRegression\n",
            "Model Number: 591 with model UnivariateRegression in generation 4 of 10\n",
            "Model Number: 592 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 593 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 594 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 595 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 110.8243\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 113.2048\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.9015\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.9596\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.6742\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.6640\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.3843\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 111.8702\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.4401\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.9693\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.1583\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.8722\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 109.1036\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.3796\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.3641\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.3605\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.3509\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.6594\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.0699\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.3382\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 110.2625\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8231\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.8239\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.5420\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.5513\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108.5881\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.9915\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.9828\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.6512\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.7352\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.3593\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.9639\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.5297\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.5662\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.4959\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.4369\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.5785\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.4761\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.2682\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.5712\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.4795\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9390\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.7220\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8903\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8872\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.2972\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.6715\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.3635\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 100.9715\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.3576\n",
            "Model Number: 596 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 597 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 598 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 598: MultivariateRegression\n",
            "Model Number: 599 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 600 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 601 with model GLS in generation 4 of 10\n",
            "Model Number: 602 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 603 with model NVAR in generation 4 of 10\n",
            "Model Number: 604 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 605 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 606 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 607 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 607: MultivariateRegression\n",
            "Model Number: 608 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 609 with model DatepartRegression in generation 4 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 11ms/step - loss: 110.8243\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 113.2048\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.9015\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 104.9596\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 105.6742\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.6640\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.3843\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 111.8702\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.4401\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.9693\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 107.1583\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.8722\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 109.1036\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.3796\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.3641\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.3605\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.3509\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.6594\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.0699\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.3382\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 110.2625\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.8231\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.8239\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.5420\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.5513\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 108.5881\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.9915\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9828\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.6512\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.7352\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.3593\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.9639\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.5297\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.5662\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.4959\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.4369\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.5785\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.4761\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.2682\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.5712\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.4795\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.9390\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.7220\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8903\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8872\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.2972\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.6715\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.3635\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 100.9715\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.3576\n",
            "New Generation: 5 of 10\n",
            "Model Number: 610 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 611 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 612 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 613 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 614 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 615 with model NVAR in generation 5 of 10\n",
            "Model Number: 616 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 617 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 618 with model MultivariateRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 618: MultivariateRegression\n",
            "Model Number: 619 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 13ms/step - loss: 108.0425\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 103.2125\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 103.8804\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.3915\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 105.2842\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.7628\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.0846\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.7922\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 107.8978\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.7871\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.6217\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.1204\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.4420\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.5497\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.5958\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.0314\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.7564\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.4171\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.5826\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.9993\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.6695\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.5046\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.7198\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8757\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 100.9383\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7597\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.3036\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.1734\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.3842\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 101.0365\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7068\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.5789\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.8970\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.1691\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.6280\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.0229\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9787\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.1226\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7747\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.0321\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.4025\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7174\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.2775\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.6769\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.8422\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.4040\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 100.3389\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 100.2759\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.6066\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.2855\n",
            "Model Number: 620 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 621 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 622 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 623 with model WindowRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 623: WindowRegression\n",
            "Model Number: 624 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 625 with model UnobservedComponents in generation 5 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 625: UnobservedComponents\n",
            "Model Number: 626 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 627 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 628 with model ETS in generation 5 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 629 with model NVAR in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 629: NVAR\n",
            "Model Number: 630 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 631 with model WindowRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 631: WindowRegression\n",
            "Model Number: 632 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 633 with model NVAR in generation 5 of 10\n",
            "Model Number: 634 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 635 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 13ms/step - loss: 460963.4688\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 276649.1250\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 349193.4375\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 374666.2500\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 240959.2188\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 152195.0781\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 208408.7812\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 244790.0312\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 75598.7344\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 178556.4844\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 198742.9844\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 235426.8594\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 242581.3438\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 94558.9844\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102354.0703\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108866.9844\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 86974.7969\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 116859.1328\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 190431.1875\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 130978.0000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 78998.2734\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105404.1719\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 81082.1172\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 80909.4766\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 97069.5547\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 122309.5938\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 55255.3047\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 64648.7695\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 68510.6484\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 68596.8750\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 36148.6172\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 57816.8711\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 60313.0664\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 57504.0430\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 134011.9688\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 37368.4805\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 78463.0078\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 46227.0625\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 66081.9609\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 39736.3164\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 64045.5547\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 49769.3516\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 55685.6211\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 48876.2617\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 36007.8242\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 45895.1914\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 28616.8262\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 50258.1680\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 41746.0234\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 44361.2500\n",
            "Model Number: 636 with model FBProphet in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 636: FBProphet\n",
            "Model Number: 637 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 638 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 639 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 640 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 641 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 642 with model GLS in generation 5 of 10\n",
            "Model Number: 643 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 644 with model NVAR in generation 5 of 10\n",
            "Model Number: 645 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 646 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 8s 13ms/step - loss: 105.2012\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.8417\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.6158\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.7244\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.2008\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.3259\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.7555\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.8244\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.4557\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.7157\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.7513\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.6998\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.3462\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 105.3867\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.6200\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.0986\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.6219\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5731\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7910\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.4806\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.5572\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7485\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7802\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.4679\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.3409\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.6092\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 102.9780\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 100.5822\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.4330\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.3394\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.0924\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.3591\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9543\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 100.4906\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5150\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.1516\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.1319\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.3068\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8322\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.0927\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7244\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.5916\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.9952\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 100.0100\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8156\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8263\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.1472\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5161\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.0966\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.6310\n",
            "Model Number: 647 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 648 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 649 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 650 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 651 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 652 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 653 with model UnivariateMotif in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 654 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 655 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 656 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 657 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 13ms/step - loss: 231.9991\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 163.2010\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 155.2942\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 181.9343\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 136.8262\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 152.7675\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 137.2529\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 150.6527\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 120.6504\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 122.9082\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 143.9904\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 135.8363\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 125.9734\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 129.7238\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 142.1871\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 134.0988\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 154.6000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 123.1128\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 116.6633\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 134.7740\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 116.0345\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 120.7340\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 118.5410\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 139.1001\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 124.1659\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.7158\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 115.9930\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 107.5500\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 127.0221\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 119.0112\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 116.1309\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 122.9354\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 121.8035\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 114.5330\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 118.4637\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 111.4341\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 113.2066\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 109.5529\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 124.2244\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 108.7475\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.4599\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 113.7156\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 109.6191\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 109.7788\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 108.3606\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 120.0509\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 112.0549\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 106.9936\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 111.3555\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 112.7745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 658 with model WindowRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 658: WindowRegression\n",
            "Model Number: 659 with model FBProphet in generation 5 of 10\n",
            "Model Number: 660 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 661 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 662 with model SectionalMotif in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 662: SectionalMotif\n",
            "Model Number: 663 with model GLS in generation 5 of 10\n",
            "Model Number: 664 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 665 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 666 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 667 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 668 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 669 with model DatepartRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 87.4737\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 86.0150\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 85.7332\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 85.5903\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 85.4186\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 85.6547\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 85.3204\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 85.0539\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 85.0903\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.9224\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.9447\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.8088\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 84.9580\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 84.6901\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 84.6499\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 85.2083\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.3970\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.4181\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 84.2562\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 84.1993\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 84.3616\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.9397\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.1077\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.1443\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.0714\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.9916\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.7594\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.8434\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.1773\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 84.1726\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.5230\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.8700\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.3226\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 83.3736\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.5190\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.0492\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.4154\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.0042\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 83.5215\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 83.9180\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 83.3067\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 82.9532\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 82.9576\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 82.6745\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 83.4784\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 82.7137\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 82.9413\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 82.5516\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 82.5438\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 82.3842\n",
            "Model Number: 670 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 671 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 672 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 673 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 674 with model LastValueNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 675 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 676 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 677 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 678 with model AverageValueNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 678: AverageValueNaive\n",
            "Model Number: 679 with model SeasonalNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 680 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 681 with model GLS in generation 5 of 10\n",
            "Model Number: 682 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 683 with model GLS in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 684 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 685 with model FBProphet in generation 5 of 10\n",
            "Model Number: 686 with model GLS in generation 5 of 10\n",
            "Model Number: 687 with model NVAR in generation 5 of 10\n",
            "Model Number: 688 with model AverageValueNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 689 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 690 with model FBProphet in generation 5 of 10\n",
            "Model Number: 691 with model MultivariateMotif in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 692 with model FBProphet in generation 5 of 10\n",
            "Model Number: 693 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 694 with model NVAR in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 695 with model FBProphet in generation 5 of 10\n",
            "Model Number: 696 with model GLS in generation 5 of 10\n",
            "Model Number: 697 with model FBProphet in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 6 of 10\n",
            "Model Number: 698 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 699 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 700 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 701 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 702 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 703 with model WindowRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 704 with model FBProphet in generation 6 of 10\n",
            "Model Number: 705 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 706 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 707 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 707: MultivariateRegression\n",
            "Model Number: 708 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 709 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 710 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 711 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 712 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 713 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 714 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 715 with model SeasonalNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 716 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 717 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 718 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 719 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 720 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 721 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 722 with model SectionalMotif in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 723 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 724 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 725 with model SectionalMotif in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type=='User' but no future_regressor supplied\") in model 725: SectionalMotif\n",
            "Model Number: 726 with model LastValueNaive in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 726: LastValueNaive\n",
            "Model Number: 727 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 728 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 13ms/step - loss: 394.4729\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 241.2327\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 301.0645\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 232.7621\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 211.0293\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 236.7333\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 173.1340\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 183.6232\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 224.2753\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 188.8975\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 212.1304\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 253.3438\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 171.3672\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 156.9257\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 174.0159\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 158.0360\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 184.4447\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 164.9567\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 145.2760\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 140.2050\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 117.5736\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 169.7679\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 141.8652\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 131.3609\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 140.3065\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 157.5873\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 138.7092\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 144.2708\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 122.8563\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 152.7004\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 113.7362\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 139.7364\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 148.9764\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 132.6282\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 121.8100\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 138.9566\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 131.1124\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 128.5970\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 116.6617\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 139.1492\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 141.8722\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.0076\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 128.8150\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 115.9054\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 126.5771\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 129.2475\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 130.6802\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 118.9222\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 118.1665\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 117.2678\n",
            "Model Number: 729 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 730 with model GLS in generation 6 of 10\n",
            "Model Number: 731 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 732 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 733 with model UnivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float64').\") in model 733: UnivariateRegression\n",
            "Model Number: 734 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 735 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 736 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 737 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 738 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 739 with model LastValueNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 740 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 741 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 742 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 743 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 744 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 745 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 746 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 747 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 748 with model MultivariateRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 748: MultivariateRegression\n",
            "Model Number: 749 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 750 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 751 with model GLS in generation 6 of 10\n",
            "Model Number: 752 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 753 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 754 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 14ms/step - loss: 201.1321\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 130.3958\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 122.6401\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 125.6104\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 135.0981\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 117.9861\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 115.3973\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 114.7090\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 110.4794\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.0574\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 119.8084\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 112.7884\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 112.1495\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 111.0510\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 114.0770\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 108.9500\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.5383\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.8553\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 107.4930\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.1710\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.2906\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 115.0275\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.2629\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.4082\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.3841\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 102.6106\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108.3820\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 105.0445\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.8776\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.7733\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 103.6223\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 103.3575\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.2350\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7474\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.1167\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.0720\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 103.6094\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.3875\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1150\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.0729\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.1981\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.2042\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.6003\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.9258\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.2510\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7901\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.2248\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.1953\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.5600\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.0833\n",
            "Model Number: 755 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 756 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 757 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 132.8207\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 114.8957\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.0538\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 128.7978\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.9603\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108.4833\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 112.4947\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 108.7211\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.9931\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.1861\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.2902\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.5375\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.3879\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.4128\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.2717\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.5970\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4134\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9355\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.2342\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.2286\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.0772\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 107.4028\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.3064\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.9795\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 106.8180\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.9488\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.5581\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.6585\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 106.7956\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 103.0389\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 106.7005\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.3018\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.4093\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.0836\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.4785\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.3536\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.2398\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.6186\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.3191\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.7280\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.6069\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.6601\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.0301\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 104.6470\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.0182\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.7666\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.3146\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.6828\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.6481\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 101.8664\n",
            "Model Number: 758 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 759 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 759: DatepartRegression\n",
            "Model Number: 760 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 761 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 762 with model WindowRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 763 with model FBProphet in generation 6 of 10\n",
            "Model Number: 764 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 765 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 766 with model GLS in generation 6 of 10\n",
            "Model Number: 767 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 768 with model NVAR in generation 6 of 10\n",
            "Model Number: 769 with model DatepartRegression in generation 6 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 12ms/step - loss: 147.4520\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 121.5600\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 112.0746\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 116.8428\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.9925\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 113.8868\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 114.0426\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106.7449\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 111.7839\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 116.3273\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108.5917\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 108.6746\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.7448\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.1839\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.2568\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.0252\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 107.2286\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.8613\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 105.0038\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 107.6452\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.2678\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.0381\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 106.8633\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.6542\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.4858\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.5970\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1741\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.0559\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4678\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.5908\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.2262\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.4049\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.8266\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.5416\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.8501\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.4977\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.1857\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.5366\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8707\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 102.1270\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 103.4148\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.4988\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.9850\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.1134\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.8278\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.6518\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 100.9893\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.5169\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 101.5269\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.2089\n",
            "Model Number: 770 with model NVAR in generation 6 of 10\n",
            "Model Number: 771 with model ETS in generation 6 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 772 with model GLS in generation 6 of 10\n",
            "Model Number: 773 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 774 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 775 with model FBProphet in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 776 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 777 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 778 with model GLS in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 779 with model NVAR in generation 6 of 10\n",
            "Model Number: 780 with model NVAR in generation 6 of 10\n",
            "Model Number: 781 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 782 with model WindowRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 783 with model SeasonalNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 784 with model FBProphet in generation 6 of 10\n",
            "Model Number: 785 with model UnivariateRegression in generation 6 of 10\n",
            "New Generation: 7 of 10\n",
            "Model Number: 786 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 787 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 788 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 789 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 790 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 6s 15ms/step - loss: 104.4334\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 96.1029\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 96.5772\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 91.6012\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 93.5399\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 92.3823\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 89.2042\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 94.8956\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 90.9389\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 91.7781\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 93.5656\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 91.9893\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 94.1545\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 88.6914\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.6880\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 89.5981\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 90.0549\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 91.6635\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 88.7146\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 92.2178\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 89.7309\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 87.4383\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.8086\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 92.1782\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.6842\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 89.3958\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 87.6786\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 90.6263\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.1663\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.6777\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 89.4278\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88.3825\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 88.8850\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 89.5176\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 85.7406\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 91.8180\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 86.9437\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 87.0899\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 86.2751\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 88.4095\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 87.8414\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 86.8011\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 88.4475\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 86.1107\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 87.3793\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 87.7137\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 87.8162\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 86.5143\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 86.3513\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 87.6048\n",
            "Model Number: 791 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 791: MultivariateRegression\n",
            "Model Number: 792 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 793 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 794 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 795 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 796 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 797 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 798 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 799 with model UnivariateRegression in generation 7 of 10\n",
            "Model Number: 800 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 801 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 802 with model NVAR in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 803 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 4s 3ms/step - loss: 589.2702\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 6.0940\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0601\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0205\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0190\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0189\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0189\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0191\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0202\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0195\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0188\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0189\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0190\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0197\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.0194\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0195\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0198\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0193\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0197\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0194\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0198\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0200\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0192\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0190\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0193\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0194\n",
            "Model Number: 804 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 805 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 8s 14ms/step - loss: 4389792.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2110122.5000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1892578.7500\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1978014.2500\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1338191.1250\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1238175.2500\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1216479.2500\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1080821.3750\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 746585.7500\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 865946.7500\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 847239.3125\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 660838.5625\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 665908.5625\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 508787.7188\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 588854.1250\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 383992.3750\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 545921.0625\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 502860.6875\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 337100.7188\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 444567.3750\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 398512.8125\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 334964.1875\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 315389.9375\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 370595.8438\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 211506.9062\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 317278.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 355599.2812\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 291007.7188\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 241844.5312\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 271389.8438\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 271199.6250\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 294491.6250\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 279703.8750\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 212539.8594\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 265335.2500\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 228027.0781\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 198218.4688\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 172977.1406\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 257150.7812\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 259575.3438\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 200926.3594\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 211740.3125\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 183358.6406\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 233768.7031\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 192680.7188\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 219185.7812\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 144539.1406\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 257880.3906\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 174839.7500\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 234392.0000\n",
            "Model Number: 806 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 807 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 808 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 809 with model FBProphet in generation 7 of 10\n",
            "Model Number: 810 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 811 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 812 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 813 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 814 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 815 with model UnivariateMotif in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 816 with model UnivariateMotif in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 816: UnivariateMotif\n",
            "Model Number: 817 with model WindowRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 817: WindowRegression\n",
            "Model Number: 818 with model GLM in generation 7 of 10\n",
            "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 818: GLM\n",
            "Model Number: 819 with model GLS in generation 7 of 10\n",
            "Model Number: 820 with model SeasonalNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 821 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 822 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 823 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: LightGBMError('[gamma]: at least one target label is negative') in model 823: MultivariateRegression\n",
            "Model Number: 824 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 825 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 826 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 827 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 828 with model NVAR in generation 7 of 10\n",
            "Model Number: 829 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 830 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 831 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 832 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 13ms/step - loss: 99.6309\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.8440\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.9441\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.9347\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5903\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.1285\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.6146\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8161\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9016\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.3786\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.9698\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.7371\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.6565\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7931\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.5641\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.0131\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8427\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6150\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7309\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6800\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5472\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8087\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.5648\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5868\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.7503\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.6382\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6610\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.5449\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.5416\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.4575\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8515\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7221\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.4953\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6361\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.5215\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.6589\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.7632\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.4705\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.5807\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.7993\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7548\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8105\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7232\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.6781\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.5808\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.6595\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.5034\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.5204\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.5083\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7157\n",
            "Model Number: 833 with model DatepartRegression in generation 7 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 15ms/step - loss: 128.1402\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 119.3423\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 121.0210\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 114.0839\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 114.5576\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 112.2945\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 110.4085\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 110.2471\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.7774\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 109.0708\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.1938\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.7315\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.9808\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.5254\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 106.1192\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.5150\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 106.4708\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.5010\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.4910\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 105.8390\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.0457\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.2344\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.2389\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.9816\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.4734\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.5460\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.0440\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 102.5408\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.7051\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.3984\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.4259\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.0017\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.6636\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4644\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.0046\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 103.4532\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.3022\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.5313\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 101.7217\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 100.0449\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.4782\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.6118\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 102.9160\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 101.5894\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.9786\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.8262\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 101.8738\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.0672\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.5597\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.6952\n",
            "Model Number: 834 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 835 with model GLS in generation 7 of 10\n",
            "Model Number: 836 with model NVAR in generation 7 of 10\n",
            "Model Number: 837 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 838 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 839 with model MultivariateRegression in generation 7 of 10\n",
            "Template Eval Error: LightGBMError('[gamma]: at least one target label is negative') in model 839: MultivariateRegression\n",
            "Model Number: 840 with model NVAR in generation 7 of 10\n",
            "Model Number: 841 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 842 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 843 with model GLS in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 843: GLS\n",
            "Model Number: 844 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 845 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 846 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 847 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 848 with model GLS in generation 7 of 10\n",
            "Model Number: 849 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 850 with model LastValueNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 850: LastValueNaive\n",
            "Model Number: 851 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 852 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 853 with model LastValueNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 854 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 854: FBProphet\n",
            "Model Number: 855 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 856 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 857 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 858 with model FBProphet in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 859 with model FBProphet in generation 7 of 10\n",
            "Model Number: 860 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 861 with model AverageValueNaive in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 862 with model FBProphet in generation 7 of 10\n",
            "Model Number: 863 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 864 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 865 with model GLS in generation 7 of 10\n",
            "Model Number: 866 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 867 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 868 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 869 with model FBProphet in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 869: FBProphet\n",
            "Model Number: 870 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 871 with model ETS in generation 7 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 872 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 873 with model AverageValueNaive in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 873: AverageValueNaive\n",
            "New Generation: 8 of 10\n",
            "Model Number: 874 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 875 with model GLS in generation 8 of 10\n",
            "Model Number: 876 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 877 with model UnivariateMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 878 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 879 with model FBProphet in generation 8 of 10\n",
            "Model Number: 880 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 881 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 882 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 883 with model WindowRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 884 with model FBProphet in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 884: FBProphet\n",
            "Model Number: 885 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 886 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 887 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 887: AverageValueNaive\n",
            "Model Number: 888 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 889 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 890 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 891 with model MultivariateRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 892 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 893 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 12ms/step - loss: 475.9228\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 308.9901\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 309.0048\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 206.8346\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 284.9041\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 368.0395\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 321.1763\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 268.5830\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 293.5946\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 204.6741\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 289.2151\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 276.0102\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 231.5067\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 222.5062\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 203.9294\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 210.3854\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 186.9927\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 160.6365\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 184.7987\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 198.8121\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 153.6889\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 210.7242\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 192.7411\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 196.9327\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 167.1099\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 172.0531\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 178.4165\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 182.4624\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 159.6732\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 158.7218\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 147.7434\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 147.3805\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 161.7695\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 142.7860\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 168.3824\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 157.2925\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 148.3311\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 115.2554\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 154.8886\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 160.6517\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 161.8953\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 147.1814\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 142.8267\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 153.8672\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 132.5248\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 122.3084\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 151.9807\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 152.8724\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 145.9031\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 112.8626\n",
            "Model Number: 894 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 895 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 895: UnobservedComponents\n",
            "Model Number: 896 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 897 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 898 with model NVAR in generation 8 of 10\n",
            "Model Number: 899 with model UnivariateRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 899: UnivariateRegression\n",
            "Model Number: 900 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 901 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 902 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 903 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 904 with model DatepartRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 905 with model UnivariateMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 906 with model GLS in generation 8 of 10\n",
            "Model Number: 907 with model SeasonalNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 907: SeasonalNaive\n",
            "Model Number: 908 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 909 with model NVAR in generation 8 of 10\n",
            "Model Number: 910 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 911 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 912 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 913 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 914 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 915 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 916 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 917 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 918 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 919 with model GLS in generation 8 of 10\n",
            "Model Number: 920 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 921 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 922 with model WindowRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError('RANSAC could not find a valid consensus set. All `max_trials` iterations were skipped because each randomly chosen sub-sample failed the passing criteria. See estimator attributes for diagnostics (n_skips*).') in model 922: WindowRegression\n",
            "Model Number: 923 with model UnivariateRegression in generation 8 of 10\n",
            "Model Number: 924 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 925 with model SectionalMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 926 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 927 with model GLS in generation 8 of 10\n",
            "Model Number: 928 with model ETS in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 928: ETS\n",
            "Model Number: 929 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 930 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 931 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 932 with model ETS in generation 8 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 933 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 933: DatepartRegression\n",
            "Model Number: 934 with model ConstantNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 935 with model FBProphet in generation 8 of 10\n",
            "Model Number: 936 with model SectionalMotif in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 937 with model FBProphet in generation 8 of 10\n",
            "Model Number: 938 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 939 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 940 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 941 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 942 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 943 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 944 with model GLS in generation 8 of 10\n",
            "Model Number: 945 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 16ms/step - loss: 730.0346\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 6958.6387\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1406.4929\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1714.6508\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3590.8201\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2094.8845\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1565.1256\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3261.3376\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1689.0249\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 849.1585\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3909.5693\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 704.4435\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 4515.9995\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1768.1144\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1762.3579\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 975.5951\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2046.4019\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1555.5869\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 759.6343\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1855.3312\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1007.7063\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 572.2507\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1460.7117\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 809.9586\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 3062.3616\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 583.4419\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 1476.6764\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1034.1941\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2386.1057\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1048.1404\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 518.0107\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1210.1743\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1749.0679\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 709.1980\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 500.4532\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1483.5266\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1099.7780\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1209.6254\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1145.2828\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1415.5378\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 249.3102\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1729.6681\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1377.7383\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 774.6252\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 957.3001\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 902.6984\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 417.7708\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 1056.2241\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1293.9047\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 399.9571\n",
            "Model Number: 946 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 947 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 948 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 949 with model GLS in generation 8 of 10\n",
            "Model Number: 950 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 951 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 952 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 952: DatepartRegression\n",
            "Model Number: 953 with model LastValueNaive in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 953: LastValueNaive\n",
            "Model Number: 954 with model FBProphet in generation 8 of 10\n",
            "Model Number: 955 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 956 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 957 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 15ms/step - loss: 99.9988\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.9974\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.9957\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9949\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9930\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9894\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9875\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9836\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.9786\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9758\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9723\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9668\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9673\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9598\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9606\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9564\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9530\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9500\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9496\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9464\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9452\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 99.9443\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9427\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9415\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9393\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9380\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9367\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9369\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9357\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9342\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9329\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9317\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9318\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9303\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9295\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9285\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 99.9273\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9265\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9257\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9250\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9242\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9235\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9222\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9210\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9207\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9180\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9166\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9149\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.9119\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9120\n",
            "Model Number: 958 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 959 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 960 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 961 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "41/41 [==============================] - 5s 4ms/step - loss: 600.8757\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.2477\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0644\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0224\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 0.0209\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0211\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0222\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0214\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0211\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0209\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0208\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0208\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0217\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0215\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0218\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0217\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0217\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0218\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0222\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "New Generation: 9 of 10\n",
            "Model Number: 962 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 963 with model UnivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:331: RuntimeWarning: divide by zero encountered in power\n",
            "  + np.power(y_pred, 2 - p) / (2 - p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 964 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 965 with model AverageValueNaive in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 966 with model AverageValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 966: AverageValueNaive\n",
            "Model Number: 967 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 968 with model FBProphet in generation 9 of 10\n",
            "Model Number: 969 with model DatepartRegression in generation 9 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 12ms/step - loss: 531663.0000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 252284.8750\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 145639.1562\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 122588.5000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 141463.0625\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 73106.5938\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 113151.7891\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 39141.2578\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 93820.8594\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 59520.7031\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 53845.9531\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 94006.8750\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 56148.2500\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 32174.1211\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 88538.1016\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 25065.9980\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 50433.5742\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 40902.5625\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 72817.8594\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 40886.5547\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 55459.2969\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 6028.5815\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 30350.5723\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1817.7683\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 73332.4375\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 20158.7012\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 71988.3828\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 37370.1055\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 26509.7285\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 38836.2852\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 10556.9385\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 64172.6758\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 24677.7949\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 54722.2422\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 34387.4844\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 45522.8828\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 24845.4551\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 40703.4570\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 31462.3867\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 7188.5254\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 39112.4492\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 27077.3379\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 40034.0586\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 19130.1445\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 32805.5430\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 24529.9668\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 31362.5332\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 39995.5039\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 23749.3594\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 20348.0938\n",
            "Model Number: 970 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 971 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 972 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 973 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 974 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 975 with model DatepartRegression in generation 9 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 12ms/step - loss: 100.1182\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8670\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.7870\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 99.8262\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8236\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8688\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8744\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.7854\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8265\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8667\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8174\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8110\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 99.8759\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8741\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6970\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 99.8612\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.8432\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8574\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8992\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8420\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8693\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8615\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8005\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8076\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7589\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.7590\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.8671\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 99.7798\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8318\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.8093\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8059\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7757\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.7740\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.9032\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8216\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8509\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.8332\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.6814\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.9217\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7703\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.7576\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.7836\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.8120\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.7161\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7756\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 99.8375\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 99.7981\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7731\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 99.7372\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 99.7791\n",
            "Model Number: 976 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 977 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 978 with model NVAR in generation 9 of 10\n",
            "Model Number: 979 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 980 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 981 with model GLS in generation 9 of 10\n",
            "Model Number: 982 with model SeasonalNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 982: SeasonalNaive\n",
            "Model Number: 983 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 984 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 985 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 986 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 987 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 988 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 989 with model GLS in generation 9 of 10\n",
            "Model Number: 990 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 991 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 992 with model DatepartRegression in generation 9 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 13ms/step - loss: 146.7136\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 133.5309\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 117.2367\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 184.3361\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4565\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 117.6812\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 121.0193\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 107.1506\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 122.8147\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 114.0047\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 106.5025\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 118.7826\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 109.8737\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 117.1628\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 109.6832\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 106.9323\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 119.7395\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 110.1828\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.2401\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 111.1905\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 109.9185\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.2305\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.9900\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 108.4598\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.2587\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.7336\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.5099\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.0887\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.7140\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.5236\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 103.3324\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.4568\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 106.8214\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 104.1939\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 104.7784\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.3212\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 103.3129\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 105.1857\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.8470\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 109.1279\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.6815\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 101.7033\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.4835\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 108.0559\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 100.1676\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.2792\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.3471\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 100.7401\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.0798\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.5880\n",
            "Model Number: 993 with model GLM in generation 9 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 993: GLM\n",
            "Model Number: 994 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 995 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 996 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 997 with model GLS in generation 9 of 10\n",
            "Model Number: 998 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 999 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1000 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "ETS failed on description with ValueError('endog must be strictly positive when using multiplicative trend or seasonal components.')\n",
            "Model Number: 1001 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1002 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1003 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1004 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 1005 with model GLM in generation 9 of 10\n",
            "Model Number: 1006 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1007 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1008 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1009 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1010 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1011 with model GLS in generation 9 of 10\n",
            "Model Number: 1012 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1013 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1014 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1015 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1016 with model DatepartRegression in generation 9 of 10\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 4ms/step - loss: 589.3547\n",
            "Epoch 2/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.7693\n",
            "Epoch 3/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6906\n",
            "Epoch 4/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6356\n",
            "Epoch 5/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6325\n",
            "Epoch 6/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6373\n",
            "Epoch 7/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6347\n",
            "Epoch 8/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6346\n",
            "Epoch 9/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6342\n",
            "Epoch 10/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6370\n",
            "Epoch 11/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.6446\n",
            "Epoch 12/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.6353\n",
            "Epoch 13/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6336\n",
            "Epoch 14/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6363\n",
            "Epoch 15/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6442\n",
            "Epoch 16/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6391\n",
            "Epoch 17/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6367\n",
            "Epoch 18/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6345\n",
            "Epoch 19/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6343\n",
            "Epoch 20/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6340\n",
            "Epoch 21/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6342\n",
            "Epoch 22/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6352\n",
            "Epoch 23/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6418\n",
            "Epoch 24/50\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 0.6387\n",
            "Epoch 25/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6524\n",
            "Epoch 26/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6406\n",
            "Epoch 27/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6333\n",
            "Epoch 28/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6424\n",
            "Epoch 29/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6488\n",
            "Epoch 30/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6476\n",
            "Epoch 31/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6351\n",
            "Epoch 32/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6283\n",
            "Epoch 33/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6389\n",
            "Epoch 34/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6451\n",
            "Epoch 35/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6625\n",
            "Epoch 36/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6687\n",
            "Epoch 37/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6511\n",
            "Epoch 38/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6596\n",
            "Epoch 39/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6438\n",
            "Epoch 40/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6603\n",
            "Epoch 41/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6708\n",
            "Epoch 42/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6599\n",
            "Epoch 43/50\n",
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6543\n",
            "Epoch 44/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6388\n",
            "Epoch 45/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6652\n",
            "Epoch 46/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6908\n",
            "Epoch 47/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6527\n",
            "Epoch 48/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6427\n",
            "Epoch 49/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6385\n",
            "Epoch 50/50\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.6496\n",
            "Model Number: 1017 with model UnivariateMotif in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1017: UnivariateMotif\n",
            "Model Number: 1018 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1019 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1019: UnobservedComponents\n",
            "Model Number: 1020 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1021 with model ETS in generation 9 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 1022 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1023 with model NVAR in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1024 with model FBProphet in generation 9 of 10\n",
            "Model Number: 1025 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1026 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1027 with model UnivariateRegression in generation 9 of 10\n",
            "Model Number: 1028 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1029 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1030 with model AverageValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1030: AverageValueNaive\n",
            "Model Number: 1031 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1032 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1033 with model SeasonalNaive in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1034 with model GLS in generation 9 of 10\n",
            "Model Number: 1035 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1036 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1036: DatepartRegression\n",
            "Model Number: 1037 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1038 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1039 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1040 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1041 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1042 with model NVAR in generation 9 of 10\n",
            "Model Number: 1043 with model GLS in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1044 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1045 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: ValueError('Provided exogenous values are not of the appropriate shape. Required (20, 1), got (20,).') in model 1045: UnobservedComponents\n",
            "Model Number: 1046 with model AverageValueNaive in generation 9 of 10\n",
            "Model Number: 1047 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1048 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1049 with model MultivariateRegression in generation 9 of 10\n",
            "New Generation: 10 of 10\n",
            "Model Number: 1050 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1051 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1052 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1053 with model GLS in generation 10 of 10\n",
            "Model Number: 1054 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 64.0793\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 54.9712\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 54.4543\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 51.8580\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 52.2790\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 53.0976\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 52.8487\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 53.1251\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 51.0834\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 52.7358\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 50.3007\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 51.4402\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 48.7240\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 49.9545\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 48.6543\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 48.1407\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 48.7064\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 48.5988\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 47.9859\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 47.1692\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 44.7904\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 46.5451\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 43.8518\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 44.0085\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 42.0757\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 43.3555\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 43.8446\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 43.7192\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 41.2523\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 41.4715\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 44.3001\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 42.4612\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 41.9340\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 42.4771\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 39.8557\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 43.4446\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 40.2849\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 40.7310\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 40.7486\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 40.0961\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 39.6136\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 39.3602\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 40.0949\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 39.2173\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 39.8628\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 38.2797\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 38.1589\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 37.5985\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 37.2423\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 36.2627\n",
            "Model Number: 1055 with model SectionalMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1056 with model FBProphet in generation 10 of 10\n",
            "Model Number: 1057 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1058 with model ETS in generation 10 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 1059 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1060 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1061 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1062 with model NVAR in generation 10 of 10\n",
            "Model Number: 1063 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1064 with model GLS in generation 10 of 10\n",
            "Model Number: 1065 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1066 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1067 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1068 with model SectionalMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 1068: SectionalMotif\n",
            "Model Number: 1069 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1069: WindowRegression\n",
            "Model Number: 1070 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1071 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1072 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1073 with model MultivariateMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1074 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1075 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1076 with model FBProphet in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1077 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1078 with model GLS in generation 10 of 10\n",
            "Model Number: 1079 with model FBProphet in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1080 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1081 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1082 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1083 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1084 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1085 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1086 with model SeasonalNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1087 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1088 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1089 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1090 with model SectionalMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  res *= (1 - noise / lVar)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/signal/signaltools.py:1611: RuntimeWarning: invalid value encountered in multiply\n",
            "  res *= (1 - noise / lVar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1091 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1092 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1093 with model DatepartRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:42: RuntimeWarning: invalid value encountered in multiply\n",
            "  temp = d1 * family.deviance_derivative(y, y_pred, weights)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in log\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:326: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (np.log(y_pred / y) + y / y_pred - 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1094 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1095 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1096 with model WindowRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1097 with model ETS in generation 10 of 10\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "Model Number: 1098 with model NVAR in generation 10 of 10\n",
            "Model Number: 1099 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1100 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1101 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1102 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1103 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1104 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 7s 14ms/step - loss: 251.9023\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 163.9274\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 143.8464\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 138.0169\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 140.9505\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 138.9802\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 125.6517\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 133.4591\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 121.0055\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 121.6711\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 118.6240\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 128.5800\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 114.6546\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 112.0904\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 127.1376\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 113.3015\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 120.0464\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.3133\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 111.2845\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 119.2654\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 113.7610\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 110.6548\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 113.6034\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 108.9795\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 109.8080\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 112.7790\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.9337\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 115.8119\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 104.4946\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 102.1702\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.7448\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.5501\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 107.4894\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 107.7179\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 104.3365\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 109.0654\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 101.5184\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.4506\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 105.5295\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 111.8362\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.3432\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 105.9780\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 106.8779\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 102.7017\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 102.5778\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 110.0701\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 107.2215\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 103.3432\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 104.8395\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 17ms/step - loss: 102.1877\n",
            "Model Number: 1105 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1106 with model UnobservedComponents in generation 10 of 10\n",
            "Model Number: 1107 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1107: DatepartRegression\n",
            "Model Number: 1108 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1108: WindowRegression\n",
            "Model Number: 1109 with model FBProphet in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer STLFilter failed on fit') in model 1109: FBProphet\n",
            "Model Number: 1110 with model AverageValueNaive in generation 10 of 10\n",
            "Model Number: 1111 with model LastValueNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1112 with model GLS in generation 10 of 10\n",
            "Model Number: 1113 with model GLS in generation 10 of 10\n",
            "Model Number: 1114 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1115 with model MultivariateRegression in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1116 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1117 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1118 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1119 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1120 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1121 with model Ensemble in generation 11 of Ensembles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1122 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1123 with model Ensemble in generation 11 of Ensembles\n",
            "Validation Round: 1\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 1\n",
            "📈 1 - Ensemble with avg smape 16.79: \n",
            "Model Number: 2 of 155 with model Ensemble for Validation 1\n",
            "2 - Ensemble with avg smape 17.68: \n",
            "Model Number: 3 of 155 with model Ensemble for Validation 1\n",
            "3 - Ensemble with avg smape 19.11: \n",
            "Model Number: 4 of 155 with model Ensemble for Validation 1\n",
            "4 - Ensemble with avg smape 31.65: \n",
            "Model Number: 5 of 155 with model Ensemble for Validation 1\n",
            "5 - Ensemble with avg smape 18.35: \n",
            "Model Number: 6 of 155 with model Ensemble for Validation 1\n",
            "6 - Ensemble with avg smape 32.72: \n",
            "Model Number: 7 of 155 with model Ensemble for Validation 1\n",
            "7 - Ensemble with avg smape 32.72: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 8 - Ensemble with avg smape 16.39: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 1\n",
            "9 - UnivariateMotif with avg smape 20.25: \n",
            "Model Number: 10 of 155 with model UnivariateMotif for Validation 1\n",
            "10 - UnivariateMotif with avg smape 20.25: \n",
            "Model Number: 11 of 155 with model UnivariateMotif for Validation 1\n",
            "11 - UnivariateMotif with avg smape 19.76: \n",
            "Model Number: 12 of 155 with model UnivariateMotif for Validation 1\n",
            "12 - UnivariateMotif with avg smape 19.76: \n",
            "Model Number: 13 of 155 with model SectionalMotif for Validation 1\n",
            "13 - SectionalMotif with avg smape 18.93: \n",
            "Model Number: 14 of 155 with model SectionalMotif for Validation 1\n",
            "14 - SectionalMotif with avg smape 19.05: \n",
            "Model Number: 15 of 155 with model UnivariateMotif for Validation 1\n",
            "15 - UnivariateMotif with avg smape 21.74: \n",
            "Model Number: 16 of 155 with model SectionalMotif for Validation 1\n",
            "16 - SectionalMotif with avg smape 16.74: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 1\n",
            "17 - UnivariateMotif with avg smape 19.99: \n",
            "Model Number: 18 of 155 with model SectionalMotif for Validation 1\n",
            "18 - SectionalMotif with avg smape 18.16: \n",
            "Model Number: 19 of 155 with model SectionalMotif for Validation 1\n",
            "19 - SectionalMotif with avg smape 18.16: \n",
            "Model Number: 20 of 155 with model SectionalMotif for Validation 1\n",
            "20 - SectionalMotif with avg smape 18.09: \n",
            "Model Number: 21 of 155 with model UnivariateMotif for Validation 1\n",
            "21 - UnivariateMotif with avg smape 17.66: \n",
            "Model Number: 22 of 155 with model SectionalMotif for Validation 1\n",
            "📈 22 - SectionalMotif with avg smape 16.35: \n",
            "Model Number: 23 of 155 with model SectionalMotif for Validation 1\n",
            "📈 23 - SectionalMotif with avg smape 16.25: \n",
            "Model Number: 24 of 155 with model SectionalMotif for Validation 1\n",
            "24 - SectionalMotif with avg smape 16.86: \n",
            "Model Number: 25 of 155 with model UnivariateMotif for Validation 1\n",
            "25 - UnivariateMotif with avg smape 18.7: \n",
            "Model Number: 26 of 155 with model UnivariateMotif for Validation 1\n",
            "26 - UnivariateMotif with avg smape 18.72: \n",
            "Model Number: 27 of 155 with model LastValueNaive for Validation 1\n",
            "27 - LastValueNaive with avg smape 57.76: \n",
            "Model Number: 28 of 155 with model LastValueNaive for Validation 1\n",
            "28 - LastValueNaive with avg smape 57.33: \n",
            "Model Number: 29 of 155 with model LastValueNaive for Validation 1\n",
            "29 - LastValueNaive with avg smape 57.35: \n",
            "Model Number: 30 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 - FBProphet with avg smape 24.78: \n",
            "Model Number: 31 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 - FBProphet with avg smape 28.14: \n",
            "Model Number: 32 of 155 with model FBProphet for Validation 1\n",
            "32 - FBProphet with avg smape 24.6: \n",
            "Model Number: 33 of 155 with model LastValueNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 - LastValueNaive with avg smape 58.75: \n",
            "Model Number: 34 of 155 with model FBProphet for Validation 1\n",
            "34 - FBProphet with avg smape 23.24: \n",
            "Model Number: 35 of 155 with model MultivariateMotif for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 35 - MultivariateMotif with avg smape 16.08: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 1\n",
            "36 - FBProphet with avg smape 27.96: \n",
            "Model Number: 37 of 155 with model MultivariateMotif for Validation 1\n",
            "37 - MultivariateMotif with avg smape 18.43: \n",
            "Model Number: 38 of 155 with model MultivariateMotif for Validation 1\n",
            "38 - MultivariateMotif with avg smape 21.86: \n",
            "Model Number: 39 of 155 with model MultivariateMotif for Validation 1\n",
            "39 - MultivariateMotif with avg smape 21.86: \n",
            "Model Number: 40 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 - FBProphet with avg smape 29.29: \n",
            "Model Number: 41 of 155 with model LastValueNaive for Validation 1\n",
            "41 - LastValueNaive with avg smape 17.18: \n",
            "Model Number: 42 of 155 with model AverageValueNaive for Validation 1\n",
            "42 - AverageValueNaive with avg smape 16.67: \n",
            "Model Number: 43 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 - FBProphet with avg smape 24.44: \n",
            "Model Number: 44 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 - FBProphet with avg smape 26.32: \n",
            "Model Number: 45 of 155 with model LastValueNaive for Validation 1\n",
            "45 - LastValueNaive with avg smape 17.14: \n",
            "Model Number: 46 of 155 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 - FBProphet with avg smape 22.68: \n",
            "Model Number: 47 of 155 with model MultivariateMotif for Validation 1\n",
            "47 - MultivariateMotif with avg smape 17.34: \n",
            "Model Number: 48 of 155 with model MultivariateRegression for Validation 1\n",
            "48 - MultivariateRegression with avg smape 29.56: \n",
            "Model Number: 49 of 155 with model MultivariateMotif for Validation 1\n",
            "49 - MultivariateMotif with avg smape 18.12: \n",
            "Model Number: 50 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "40/40 [==============================] - 5s 4ms/step - loss: 606.7330\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 7.0692\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0833\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0216\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0195\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0195\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0195\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0200\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0198\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0195\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0196\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0202\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0198\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.0197\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0200\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0203\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0206\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0207\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.0203\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.0199\n",
            "50 - DatepartRegression with avg smape 17.34: \n",
            "Model Number: 51 of 155 with model MultivariateMotif for Validation 1\n",
            "51 - MultivariateMotif with avg smape 23.72: \n",
            "Model Number: 52 of 155 with model LastValueNaive for Validation 1\n",
            "52 - LastValueNaive with avg smape 58.83: \n",
            "Model Number: 53 of 155 with model LastValueNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 - LastValueNaive with avg smape 58.83: \n",
            "Model Number: 54 of 155 with model LastValueNaive for Validation 1\n",
            "54 - LastValueNaive with avg smape 58.84: \n",
            "Model Number: 55 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 15ms/step - loss: 200.8046\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 140.3767\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 124.3689\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 134.1502\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 126.4820\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 116.6287\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 131.4864\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.1771\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 126.3633\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.0840\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.3081\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.2156\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 109.4960\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 119.3985\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 110.6041\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 109.6185\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 112.9908\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.1874\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 108.8768\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 111.9380\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 113.0422\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 106.3904\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.5817\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 104.8912\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 110.0737\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 110.4199\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.5281\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 110.3031\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.6465\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.2165\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.9803\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 103.2504\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.3482\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.3740\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 108.5432\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.3665\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.1106\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.7297\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 106.0553\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.1669\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8728\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 106.9036\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.0406\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.1018\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.1747\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.8293\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8906\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.7433\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.5738\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.9357\n",
            "55 - DatepartRegression with avg smape 17.36: \n",
            "Model Number: 56 of 155 with model MultivariateMotif for Validation 1\n",
            "56 - MultivariateMotif with avg smape 17.34: \n",
            "Model Number: 57 of 155 with model MultivariateMotif for Validation 1\n",
            "57 - MultivariateMotif with avg smape 17.34: \n",
            "Model Number: 58 of 155 with model AverageValueNaive for Validation 1\n",
            "58 - AverageValueNaive with avg smape 17.04: \n",
            "Model Number: 59 of 155 with model AverageValueNaive for Validation 1\n",
            "59 - AverageValueNaive with avg smape 17.04: \n",
            "Model Number: 60 of 155 with model WindowRegression for Validation 1\n",
            "60 - WindowRegression with avg smape 17.89: \n",
            "Model Number: 61 of 155 with model AverageValueNaive for Validation 1\n",
            "61 - AverageValueNaive with avg smape 17.04: \n",
            "Model Number: 62 of 155 with model AverageValueNaive for Validation 1\n",
            "62 - AverageValueNaive with avg smape 17.04: \n",
            "Model Number: 63 of 155 with model GLS for Validation 1\n",
            "63 - GLS with avg smape 18.41: \n",
            "Model Number: 64 of 155 with model GLS for Validation 1\n",
            "64 - GLS with avg smape 17.15: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 1\n",
            "65 - AverageValueNaive with avg smape 16.71: \n",
            "Model Number: 66 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 18ms/step - loss: 519.6343\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 422.4851\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 268.0208\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 256.9959\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 216.3393\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 284.2126\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 175.3583\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 225.0014\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 225.6353\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 250.9555\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 209.3854\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 182.2312\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 208.3875\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 165.4940\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 189.6693\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 197.2081\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 158.4030\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 152.0738\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 176.8875\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 151.3053\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 163.0757\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 140.9430\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 163.2881\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 148.3564\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 147.7050\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 161.0756\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 142.6546\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 140.9415\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 144.2956\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 131.1380\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 129.8365\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 148.4324\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 128.4984\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 128.4067\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 112.3108\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 155.4433\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 123.2581\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 147.5462\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.1777\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.4348\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 120.8544\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 135.2714\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 114.2735\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 136.1402\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 118.5436\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 126.1889\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 121.4144\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 126.8290\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.4176\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 125.9880\n",
            "66 - DatepartRegression with avg smape 17.55: \n",
            "Model Number: 67 of 155 with model AverageValueNaive for Validation 1\n",
            "67 - AverageValueNaive with avg smape 16.76: \n",
            "Model Number: 68 of 155 with model WindowRegression for Validation 1\n",
            "68 - WindowRegression with avg smape 33.98: \n",
            "Model Number: 69 of 155 with model WindowRegression for Validation 1\n",
            "69 - WindowRegression with avg smape 32.92: \n",
            "Model Number: 70 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "70 - ETS with avg smape 20.64: \n",
            "Model Number: 71 of 155 with model AverageValueNaive for Validation 1\n",
            "71 - AverageValueNaive with avg smape 17.32: \n",
            "Model Number: 72 of 155 with model AverageValueNaive for Validation 1\n",
            "72 - AverageValueNaive with avg smape 17.32: \n",
            "Model Number: 73 of 155 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - UnobservedComponents with avg smape 18.36: \n",
            "Model Number: 74 of 155 with model GLS for Validation 1\n",
            "74 - GLS with avg smape 17.33: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 1\n",
            "75 - UnobservedComponents with avg smape 17.08: \n",
            "Model Number: 76 of 155 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 - UnobservedComponents with avg smape 17.08: \n",
            "Model Number: 77 of 155 with model UnobservedComponents for Validation 1\n",
            "77 - UnobservedComponents with avg smape 16.66: \n",
            "Model Number: 78 of 155 with model DatepartRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "40/40 [==============================] - 5s 4ms/step - loss: 607.0678\n",
            "Epoch 2/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 7.5981\n",
            "Epoch 3/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.7125\n",
            "Epoch 4/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6423\n",
            "Epoch 5/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6367\n",
            "Epoch 6/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6489\n",
            "Epoch 7/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6384\n",
            "Epoch 8/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6517\n",
            "Epoch 9/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6427\n",
            "Epoch 10/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6443\n",
            "Epoch 11/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6402\n",
            "Epoch 12/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6411\n",
            "Epoch 13/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6402\n",
            "Epoch 14/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6372\n",
            "Epoch 15/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6623\n",
            "Epoch 16/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6452\n",
            "Epoch 17/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6418\n",
            "Epoch 18/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6434\n",
            "Epoch 19/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6589\n",
            "Epoch 20/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6480\n",
            "Epoch 21/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6647\n",
            "Epoch 22/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6412\n",
            "Epoch 23/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6688\n",
            "Epoch 24/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6514\n",
            "Epoch 25/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6565\n",
            "Epoch 26/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6428\n",
            "Epoch 27/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6464\n",
            "Epoch 28/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6395\n",
            "Epoch 29/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6435\n",
            "Epoch 30/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6427\n",
            "Epoch 31/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6454\n",
            "Epoch 32/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6415\n",
            "Epoch 33/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6609\n",
            "Epoch 34/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6438\n",
            "Epoch 35/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6566\n",
            "Epoch 36/50\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6615\n",
            "Epoch 37/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6522\n",
            "Epoch 38/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6438\n",
            "Epoch 39/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6527\n",
            "Epoch 40/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6799\n",
            "Epoch 41/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6560\n",
            "Epoch 42/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6835\n",
            "Epoch 43/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6801\n",
            "Epoch 44/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6798\n",
            "Epoch 45/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6694\n",
            "Epoch 46/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6898\n",
            "Epoch 47/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6532\n",
            "Epoch 48/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6788\n",
            "Epoch 49/50\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6847\n",
            "Epoch 50/50\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6447\n",
            "78 - DatepartRegression with avg smape 17.29: \n",
            "Model Number: 79 of 155 with model GLS for Validation 1\n",
            "79 - GLS with avg smape 17.13: \n",
            "Model Number: 80 of 155 with model UnobservedComponents for Validation 1\n",
            "80 - UnobservedComponents with avg smape 21.01: \n",
            "Model Number: 81 of 155 with model NVAR for Validation 1\n",
            "81 - NVAR with avg smape 82.24: \n",
            "Model Number: 82 of 155 with model NVAR for Validation 1\n",
            "82 - NVAR with avg smape 82.24: \n",
            "Model Number: 83 of 155 with model NVAR for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83 - NVAR with avg smape 43.99: \n",
            "Model Number: 84 of 155 with model ConstantNaive for Validation 1\n",
            "84 - ConstantNaive with avg smape 16.87: \n",
            "Model Number: 85 of 155 with model WindowRegression for Validation 1\n",
            "85 - WindowRegression with avg smape 16.89: \n",
            "Model Number: 86 of 155 with model ConstantNaive for Validation 1\n",
            "86 - ConstantNaive with avg smape 16.71: \n",
            "Model Number: 87 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 15ms/step - loss: 236.9731\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 162.7986\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 151.3869\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 140.4244\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 128.6244\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 148.4499\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 123.8999\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 122.9906\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 116.8885\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 136.5119\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 122.2924\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 120.5297\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.6883\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 119.4153\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 114.6067\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 116.0397\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 113.8181\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.8882\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.0401\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 112.1064\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.6046\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.0838\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 110.5206\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.2030\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.9378\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 106.2954\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 108.2986\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.6797\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.5920\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.5046\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.1178\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.4529\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.6790\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.1685\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.7059\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.3828\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 109.4808\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.9181\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 105.8939\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 107.0477\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 104.8069\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 103.8782\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 107.6384\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8613\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.1381\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.2911\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.4047\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.3877\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.8447\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.1717\n",
            "87 - DatepartRegression with avg smape 18.13: \n",
            "Model Number: 88 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 13ms/step - loss: 152.1222\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 117.4450\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 120.9278\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.5858\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.8076\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 114.1250\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 119.4828\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 116.1725\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 114.8979\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 110.9099\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 112.6778\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.6632\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 120.7211\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 111.4764\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 109.1330\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.4966\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 109.5166\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.5536\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 110.7900\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.5413\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 109.0752\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 108.3588\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.1822\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.5261\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.9207\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.3078\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.4773\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.1106\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.1574\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.4741\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.9812\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.3884\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.0099\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 103.9418\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.8426\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.9673\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.7066\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.2794\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.1763\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.9401\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.5688\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.4756\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.5903\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.5708\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 101.9970\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.3961\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.7455\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8678\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.1436\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7674\n",
            "88 - DatepartRegression with avg smape 17.81: \n",
            "Model Number: 89 of 155 with model MultivariateRegression for Validation 1\n",
            "89 - MultivariateRegression with avg smape 41.62: \n",
            "Model Number: 90 of 155 with model GLS for Validation 1\n",
            "90 - GLS with avg smape 16.7: \n",
            "Model Number: 91 of 155 with model WindowRegression for Validation 1\n",
            "91 - WindowRegression with avg smape 18.11: \n",
            "Model Number: 92 of 155 with model GLS for Validation 1\n",
            "92 - GLS with avg smape 16.73: \n",
            "Model Number: 93 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 116.0134\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.9546\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.2278\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.8298\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 106.3159\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 108.5070\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.4883\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 105.7294\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.2787\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 105.6899\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.7087\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.2868\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.1801\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.9888\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.3108\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8470\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.2061\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.3840\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.6401\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 101.1736\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 102.0013\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.7886\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.5314\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 99.1613\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.3657\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.8880\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 101.1740\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.6403\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 99.3200\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 102.7137\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.7598\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.4352\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.9858\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 100.7467\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.7028\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.9902\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.7809\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.7632\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.6703\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 99.7835\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.7803\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.0681\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.3993\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.1281\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.4035\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 100.3506\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 99.6921\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.3076\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.8534\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 99.5560\n",
            "93 - DatepartRegression with avg smape 17.4: \n",
            "Model Number: 94 of 155 with model SeasonalNaive for Validation 1\n",
            "94 - SeasonalNaive with avg smape 16.66: \n",
            "Model Number: 95 of 155 with model GLS for Validation 1\n",
            "95 - GLS with avg smape 17.94: \n",
            "Model Number: 96 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 15ms/step - loss: 161.1934\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 131.5123\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 127.9552\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 141.5107\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 126.1133\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.4981\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 126.4325\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 126.7468\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 135.2676\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 110.7542\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 113.5303\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 127.8639\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.9913\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.8306\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.3335\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 117.3479\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 110.9340\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 113.9779\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 118.9734\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 112.9907\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 108.9626\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 107.9231\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.8571\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.3996\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 110.2998\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.2503\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.2462\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.2640\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.0199\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.8290\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.0777\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.5501\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.0017\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 103.9917\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.3565\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.4099\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 112.0268\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.6585\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 107.9628\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 108.8427\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 109.2802\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 109.7300\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 108.2727\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.6360\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 107.1971\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.5674\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.9376\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.5401\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.3599\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.1832\n",
            "96 - DatepartRegression with avg smape 16.53: \n",
            "Model Number: 97 of 155 with model SeasonalNaive for Validation 1\n",
            "97 - SeasonalNaive with avg smape 16.2: \n",
            "Model Number: 98 of 155 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98 - SeasonalNaive with avg smape 16.27: \n",
            "Model Number: 99 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "99 - ETS with avg smape 21.74: \n",
            "Model Number: 100 of 155 with model SeasonalNaive for Validation 1\n",
            "100 - SeasonalNaive with avg smape 19.68: \n",
            "Model Number: 101 of 155 with model ConstantNaive for Validation 1\n",
            "101 - ConstantNaive with avg smape 17.53: \n",
            "Model Number: 102 of 155 with model SeasonalNaive for Validation 1\n",
            "102 - SeasonalNaive with avg smape 17.97: \n",
            "Model Number: 103 of 155 with model DatepartRegression for Validation 1\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 15ms/step - loss: 513.6498\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 239.3055\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 425.1493\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 257.5443\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 231.0024\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 287.1214\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 344.0242\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 267.7005\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 206.0339\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 464.3184\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 270.7090\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 208.8191\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 186.8035\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 252.9612\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 251.8646\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 209.7823\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 161.1614\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 208.3005\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 251.5166\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 175.5302\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 137.3369\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 181.5495\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 203.7855\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 150.4592\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 264.3061\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 128.2113\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 255.1528\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 173.9905\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 171.5920\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 160.5540\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 156.1533\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 166.0499\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 134.2050\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 168.8816\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 139.4591\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 173.4162\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 119.2854\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 162.7934\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 176.8331\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 150.5116\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 159.9313\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 147.6985\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 141.2541\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 119.7589\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 169.3545\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 112.4101\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 142.8541\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 219.7701\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 126.4306\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 158.9537\n",
            "103 - DatepartRegression with avg smape 17.38: \n",
            "Model Number: 104 of 155 with model GLS for Validation 1\n",
            "104 - GLS with avg smape 16.75: \n",
            "Model Number: 105 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "105 - ETS with avg smape 16.79: \n",
            "Model Number: 106 of 155 with model GLS for Validation 1\n",
            "106 - GLS with avg smape 18.06: \n",
            "Model Number: 107 of 155 with model WindowRegression for Validation 1\n",
            "107 - WindowRegression with avg smape 19.62: \n",
            "Model Number: 108 of 155 with model SeasonalNaive for Validation 1\n",
            "108 - SeasonalNaive with avg smape 16.81: \n",
            "Model Number: 109 of 155 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109 - SeasonalNaive with avg smape 16.81: \n",
            "Model Number: 110 of 155 with model MultivariateRegression for Validation 1\n",
            "110 - MultivariateRegression with avg smape 25.53: \n",
            "Model Number: 111 of 155 with model SeasonalNaive for Validation 1\n",
            "111 - SeasonalNaive with avg smape 17.1: \n",
            "Model Number: 112 of 155 with model WindowRegression for Validation 1\n",
            "112 - WindowRegression with avg smape 76.88: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113 - NVAR with avg smape 17.69: \n",
            "Model Number: 114 of 155 with model SeasonalNaive for Validation 1\n",
            "114 - SeasonalNaive with avg smape 17.47: \n",
            "Model Number: 115 of 155 with model WindowRegression for Validation 1\n",
            "115 - WindowRegression with avg smape 21.34: \n",
            "Model Number: 116 of 155 with model MultivariateRegression for Validation 1\n",
            "116 - MultivariateRegression with avg smape 111.31: \n",
            "Model Number: 117 of 155 with model NVAR for Validation 1\n",
            "117 - NVAR with avg smape 17.81: \n",
            "Model Number: 118 of 155 with model WindowRegression for Validation 1\n",
            "📈 118 - WindowRegression with avg smape 14.54: \n",
            "Model Number: 119 of 155 with model ConstantNaive for Validation 1\n",
            "119 - ConstantNaive with avg smape 17.77: \n",
            "Model Number: 120 of 155 with model NVAR for Validation 1\n",
            "120 - NVAR with avg smape 17.09: \n",
            "Model Number: 121 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "121 - ETS with avg smape 25.3: \n",
            "Model Number: 122 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "122 - ETS with avg smape 23.47: \n",
            "Model Number: 123 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "123 - ETS with avg smape 23.19: \n",
            "Model Number: 124 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "124 - ETS with avg smape 23.19: \n",
            "Model Number: 125 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "125 - ETS with avg smape 23.19: \n",
            "Model Number: 126 of 155 with model ConstantNaive for Validation 1\n",
            "126 - ConstantNaive with avg smape 17.46: \n",
            "Model Number: 127 of 155 with model NVAR for Validation 1\n",
            "127 - NVAR with avg smape 16.92: \n",
            "Model Number: 128 of 155 with model ETS for Validation 1\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "128 - ETS with avg smape 24.97: \n",
            "Model Number: 129 of 155 with model NVAR for Validation 1\n",
            "129 - NVAR with avg smape 58.85: \n",
            "Model Number: 130 of 155 with model NVAR for Validation 1\n",
            "130 - NVAR with avg smape 17.05: \n",
            "Model Number: 131 of 155 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - MultivariateRegression with avg smape 29.62: \n",
            "Model Number: 132 of 155 with model MultivariateRegression for Validation 1\n",
            "132 - MultivariateRegression with avg smape 69.69: \n",
            "Model Number: 133 of 155 with model UnivariateRegression for Validation 1\n",
            "133 - UnivariateRegression with avg smape 19.88: \n",
            "Model Number: 134 of 155 with model ConstantNaive for Validation 1\n",
            "134 - ConstantNaive with avg smape 19.88: \n",
            "Model Number: 135 of 155 with model ConstantNaive for Validation 1\n",
            "135 - ConstantNaive with avg smape 19.88: \n",
            "Model Number: 136 of 155 with model ConstantNaive for Validation 1\n",
            "136 - ConstantNaive with avg smape 19.88: \n",
            "Model Number: 137 of 155 with model ConstantNaive for Validation 1\n",
            "137 - ConstantNaive with avg smape 19.88: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 1\n",
            "138 - MultivariateRegression with avg smape 41.14: \n",
            "Model Number: 139 of 155 with model GLM for Validation 1\n",
            "139 - GLM with avg smape 37.79: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 1\n",
            "140 - MultivariateRegression with avg smape 16.68: \n",
            "Model Number: 141 of 155 with model UnobservedComponents for Validation 1\n",
            "141 - UnobservedComponents with avg smape 40.77: \n",
            "Model Number: 142 of 155 with model UnobservedComponents for Validation 1\n",
            "142 - UnobservedComponents with avg smape 40.77: \n",
            "Model Number: 143 of 155 with model UnobservedComponents for Validation 1\n",
            "143 - UnobservedComponents with avg smape 41.71: \n",
            "Model Number: 144 of 155 with model MultivariateRegression for Validation 1\n",
            "144 - MultivariateRegression with avg smape 26.55: \n",
            "Model Number: 145 of 155 with model UnobservedComponents for Validation 1\n",
            "145 - UnobservedComponents with avg smape 41.71: \n",
            "Model Number: 146 of 155 with model UnivariateRegression for Validation 1\n",
            "146 - UnivariateRegression with avg smape 23.9: \n",
            "Model Number: 147 of 155 with model UnivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147 - UnivariateRegression with avg smape 22.52: \n",
            "Model Number: 148 of 155 with model UnivariateRegression for Validation 1\n",
            "148 - UnivariateRegression with avg smape 22.62: \n",
            "Model Number: 149 of 155 with model UnivariateRegression for Validation 1\n",
            "149 - UnivariateRegression with avg smape 27.45: \n",
            "Model Number: 150 of 155 with model UnivariateRegression for Validation 1\n",
            "150 - UnivariateRegression with avg smape 28.63: \n",
            "Model Number: 151 of 155 with model UnivariateRegression for Validation 1\n",
            "151 - UnivariateRegression with avg smape 38.0: \n",
            "Model Number: 152 of 155 with model GLM for Validation 1\n",
            "152 - GLM with avg smape 36.46: \n",
            "Model Number: 153 of 155 with model UnivariateRegression for Validation 1\n",
            "153 - UnivariateRegression with avg smape 54.93: \n",
            "Model Number: 154 of 155 with model GLM for Validation 1\n",
            "154 - GLM with avg smape 59.7: \n",
            "Model Number: 155 of 155 with model UnivariateRegression for Validation 1\n",
            "155 - UnivariateRegression with avg smape 72.13: \n",
            "Validation Round: 2\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 2\n",
            "📈 1 - Ensemble with avg smape 31.8: \n",
            "Model Number: 2 of 155 with model Ensemble for Validation 2\n",
            "2 - Ensemble with avg smape 32.84: \n",
            "Model Number: 3 of 155 with model Ensemble for Validation 2\n",
            "3 - Ensemble with avg smape 32.1: \n",
            "Model Number: 4 of 155 with model Ensemble for Validation 2\n",
            "4 - Ensemble with avg smape 32.31: \n",
            "Model Number: 5 of 155 with model Ensemble for Validation 2\n",
            "📈 5 - Ensemble with avg smape 31.79: \n",
            "Model Number: 6 of 155 with model Ensemble for Validation 2\n",
            "6 - Ensemble with avg smape 32.6: \n",
            "Model Number: 7 of 155 with model Ensemble for Validation 2\n",
            "7 - Ensemble with avg smape 32.6: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 8 - Ensemble with avg smape 30.8: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 2\n",
            "9 - UnivariateMotif with avg smape 32.46: \n",
            "Model Number: 10 of 155 with model UnivariateMotif for Validation 2\n",
            "10 - UnivariateMotif with avg smape 32.46: \n",
            "Model Number: 11 of 155 with model UnivariateMotif for Validation 2\n",
            "11 - UnivariateMotif with avg smape 33.01: \n",
            "Model Number: 12 of 155 with model UnivariateMotif for Validation 2\n",
            "12 - UnivariateMotif with avg smape 33.01: \n",
            "Model Number: 13 of 155 with model SectionalMotif for Validation 2\n",
            "13 - SectionalMotif with avg smape 39.13: \n",
            "Model Number: 14 of 155 with model SectionalMotif for Validation 2\n",
            "14 - SectionalMotif with avg smape 39.3: \n",
            "Model Number: 15 of 155 with model UnivariateMotif for Validation 2\n",
            "15 - UnivariateMotif with avg smape 32.82: \n",
            "Model Number: 16 of 155 with model SectionalMotif for Validation 2\n",
            "16 - SectionalMotif with avg smape 37.47: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 2\n",
            "17 - UnivariateMotif with avg smape 33.79: \n",
            "Model Number: 18 of 155 with model SectionalMotif for Validation 2\n",
            "18 - SectionalMotif with avg smape 39.6: \n",
            "Model Number: 19 of 155 with model SectionalMotif for Validation 2\n",
            "19 - SectionalMotif with avg smape 39.63: \n",
            "Model Number: 20 of 155 with model SectionalMotif for Validation 2\n",
            "20 - SectionalMotif with avg smape 39.58: \n",
            "Model Number: 21 of 155 with model UnivariateMotif for Validation 2\n",
            "21 - UnivariateMotif with avg smape 32.59: \n",
            "Model Number: 22 of 155 with model SectionalMotif for Validation 2\n",
            "22 - SectionalMotif with avg smape 37.35: \n",
            "Model Number: 23 of 155 with model SectionalMotif for Validation 2\n",
            "23 - SectionalMotif with avg smape 37.13: \n",
            "Model Number: 24 of 155 with model SectionalMotif for Validation 2\n",
            "24 - SectionalMotif with avg smape 37.43: \n",
            "Model Number: 25 of 155 with model UnivariateMotif for Validation 2\n",
            "25 - UnivariateMotif with avg smape 33.74: \n",
            "Model Number: 26 of 155 with model UnivariateMotif for Validation 2\n",
            "26 - UnivariateMotif with avg smape 33.78: \n",
            "Model Number: 27 of 155 with model LastValueNaive for Validation 2\n",
            "27 - LastValueNaive with avg smape 80.36: \n",
            "Model Number: 28 of 155 with model LastValueNaive for Validation 2\n",
            "28 - LastValueNaive with avg smape 78.81: \n",
            "Model Number: 29 of 155 with model LastValueNaive for Validation 2\n",
            "29 - LastValueNaive with avg smape 78.64: \n",
            "Model Number: 30 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 - FBProphet with avg smape 31.03: \n",
            "Model Number: 31 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 - FBProphet with avg smape 31.5: \n",
            "Model Number: 32 of 155 with model FBProphet for Validation 2\n",
            "32 - FBProphet with avg smape 30.91: \n",
            "Model Number: 33 of 155 with model LastValueNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 - LastValueNaive with avg smape 82.11: \n",
            "Model Number: 34 of 155 with model FBProphet for Validation 2\n",
            "34 - FBProphet with avg smape 32.12: \n",
            "Model Number: 35 of 155 with model MultivariateMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 - MultivariateMotif with avg smape 36.45: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 2\n",
            "36 - FBProphet with avg smape 31.5: \n",
            "Model Number: 37 of 155 with model MultivariateMotif for Validation 2\n",
            "37 - MultivariateMotif with avg smape 49.9: \n",
            "Model Number: 38 of 155 with model MultivariateMotif for Validation 2\n",
            "38 - MultivariateMotif with avg smape 50.19: \n",
            "Model Number: 39 of 155 with model MultivariateMotif for Validation 2\n",
            "39 - MultivariateMotif with avg smape 50.19: \n",
            "Model Number: 40 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 - FBProphet with avg smape 32.81: \n",
            "Model Number: 41 of 155 with model LastValueNaive for Validation 2\n",
            "41 - LastValueNaive with avg smape 71.58: \n",
            "Model Number: 42 of 155 with model AverageValueNaive for Validation 2\n",
            "42 - AverageValueNaive with avg smape 32.45: \n",
            "Model Number: 43 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 43 - FBProphet with avg smape 30.78: \n",
            "Model Number: 44 of 155 with model FBProphet for Validation 2\n",
            "44 - FBProphet with avg smape 31.82: \n",
            "Model Number: 45 of 155 with model LastValueNaive for Validation 2\n",
            "45 - LastValueNaive with avg smape 71.59: \n",
            "Model Number: 46 of 155 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 46 - FBProphet with avg smape 30.64: \n",
            "Model Number: 47 of 155 with model MultivariateMotif for Validation 2\n",
            "47 - MultivariateMotif with avg smape 31.63: \n",
            "Model Number: 48 of 155 with model MultivariateRegression for Validation 2\n",
            "48 - MultivariateRegression with avg smape 44.43: \n",
            "Model Number: 49 of 155 with model MultivariateMotif for Validation 2\n",
            "49 - MultivariateMotif with avg smape 36.84: \n",
            "Model Number: 50 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "39/39 [==============================] - 5s 5ms/step - loss: 625.5299\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 8.1014\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1145\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0222\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0201\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0204\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0202\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0203\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0201\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0202\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0204\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0201\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0205\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0204\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0203\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0205\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "50 - DatepartRegression with avg smape 42.85: \n",
            "Model Number: 51 of 155 with model MultivariateMotif for Validation 2\n",
            "51 - MultivariateMotif with avg smape 33.24: \n",
            "Model Number: 52 of 155 with model LastValueNaive for Validation 2\n",
            "52 - LastValueNaive with avg smape 69.06: \n",
            "Model Number: 53 of 155 with model LastValueNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 - LastValueNaive with avg smape 69.06: \n",
            "Model Number: 54 of 155 with model LastValueNaive for Validation 2\n",
            "54 - LastValueNaive with avg smape 69.06: \n",
            "Model Number: 55 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 14ms/step - loss: 200.1608\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 146.0676\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 176.0769\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 140.4179\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 120.1621\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 154.5484\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 138.5074\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 137.5619\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 129.3261\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 125.9529\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 114.8513\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 129.2192\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 122.2414\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 126.9413\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.1786\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 124.8314\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 121.3549\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 121.0951\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 129.9148\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 117.9010\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.8205\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.3991\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 113.8048\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 128.5906\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.8769\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.6403\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 129.5461\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.8299\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 110.9089\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 106.3701\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 113.7348\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.3905\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.2025\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 109.0008\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 111.5824\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.2312\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 112.8207\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 107.0106\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 112.7218\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.4932\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 112.3073\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.6901\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 111.3464\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 108.7116\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 111.3913\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.6242\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 103.0187\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 108.0100\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.2065\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 106.7273\n",
            "55 - DatepartRegression with avg smape 30.73: \n",
            "Model Number: 56 of 155 with model MultivariateMotif for Validation 2\n",
            "56 - MultivariateMotif with avg smape 39.57: \n",
            "Model Number: 57 of 155 with model MultivariateMotif for Validation 2\n",
            "57 - MultivariateMotif with avg smape 39.57: \n",
            "Model Number: 58 of 155 with model AverageValueNaive for Validation 2\n",
            "📈 58 - AverageValueNaive with avg smape 30.1: \n",
            "Model Number: 59 of 155 with model AverageValueNaive for Validation 2\n",
            "59 - AverageValueNaive with avg smape 30.11: \n",
            "Model Number: 60 of 155 with model WindowRegression for Validation 2\n",
            "60 - WindowRegression with avg smape 65.87: \n",
            "Model Number: 61 of 155 with model AverageValueNaive for Validation 2\n",
            "61 - AverageValueNaive with avg smape 30.11: \n",
            "Model Number: 62 of 155 with model AverageValueNaive for Validation 2\n",
            "62 - AverageValueNaive with avg smape 30.11: \n",
            "Model Number: 63 of 155 with model GLS for Validation 2\n",
            "63 - GLS with avg smape 31.4: \n",
            "Model Number: 64 of 155 with model GLS for Validation 2\n",
            "64 - GLS with avg smape 31.88: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 2\n",
            "📈 65 - AverageValueNaive with avg smape 29.82: \n",
            "Model Number: 66 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 13ms/step - loss: 463.2244\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 242.7848\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 252.0568\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 188.7738\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 197.0025\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 209.3166\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 187.1752\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 191.8763\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 166.8464\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 177.5580\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 136.4494\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 136.3012\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 157.7071\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 136.1607\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 154.2133\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 134.6621\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 141.2456\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 128.9331\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 123.4897\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 131.0936\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 126.9883\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 126.4409\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 124.3026\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 117.5693\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 153.0765\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 108.9386\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 134.5561\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 114.6350\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 117.1329\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 118.2449\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 121.0985\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 120.2094\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 115.4226\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.5378\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 117.8412\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 109.2437\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 121.8869\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 118.9750\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 118.8782\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 119.1823\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 112.9064\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 112.1081\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 113.1063\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 113.0492\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 114.9497\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.4387\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 111.4979\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 121.5255\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 111.0143\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.5351\n",
            "66 - DatepartRegression with avg smape 30.58: \n",
            "Model Number: 67 of 155 with model AverageValueNaive for Validation 2\n",
            "📈 67 - AverageValueNaive with avg smape 29.76: \n",
            "Model Number: 68 of 155 with model WindowRegression for Validation 2\n",
            "68 - WindowRegression with avg smape 69.89: \n",
            "Model Number: 69 of 155 with model WindowRegression for Validation 2\n",
            "69 - WindowRegression with avg smape 69.44: \n",
            "Model Number: 70 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "70 - ETS with avg smape 33.1: \n",
            "Model Number: 71 of 155 with model AverageValueNaive for Validation 2\n",
            "71 - AverageValueNaive with avg smape 30.52: \n",
            "Model Number: 72 of 155 with model AverageValueNaive for Validation 2\n",
            "72 - AverageValueNaive with avg smape 30.52: \n",
            "Model Number: 73 of 155 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - UnobservedComponents with avg smape 32.94: \n",
            "Model Number: 74 of 155 with model GLS for Validation 2\n",
            "74 - GLS with avg smape 33.05: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 2\n",
            "75 - UnobservedComponents with avg smape 32.74: \n",
            "Model Number: 76 of 155 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 - UnobservedComponents with avg smape 32.74: \n",
            "Model Number: 77 of 155 with model UnobservedComponents for Validation 2\n",
            "77 - UnobservedComponents with avg smape 32.02: \n",
            "Model Number: 78 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "39/39 [==============================] - 5s 4ms/step - loss: 626.6610\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 8.6777\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.7139\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6469\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6460\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6480\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6446\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6432\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6466\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6431\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6442\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6436\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6557\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6460\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6468\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6448\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6524\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6410\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6461\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6506\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6585\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6510\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6511\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6500\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6492\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6486\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6465\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6465\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6544\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6497\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6540\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6689\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6573\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6474\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6509\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6518\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6596\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6574\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6723\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6510\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6564\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6629\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6516\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6574\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6519\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6586\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6515\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6924\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.6591\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.6529\n",
            "78 - DatepartRegression with avg smape 47.86: \n",
            "Model Number: 79 of 155 with model GLS for Validation 2\n",
            "79 - GLS with avg smape 31.9: \n",
            "Model Number: 80 of 155 with model UnobservedComponents for Validation 2\n",
            "80 - UnobservedComponents with avg smape 34.6: \n",
            "Model Number: 81 of 155 with model NVAR for Validation 2\n",
            "81 - NVAR with avg smape 96.58: \n",
            "Model Number: 82 of 155 with model NVAR for Validation 2\n",
            "82 - NVAR with avg smape 96.58: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 83 of 155 with model NVAR for Validation 2\n",
            "83 - NVAR with avg smape 71.56: \n",
            "Model Number: 84 of 155 with model ConstantNaive for Validation 2\n",
            "84 - ConstantNaive with avg smape 30.18: \n",
            "Model Number: 85 of 155 with model WindowRegression for Validation 2\n",
            "85 - WindowRegression with avg smape 49.8: \n",
            "Model Number: 86 of 155 with model ConstantNaive for Validation 2\n",
            "86 - ConstantNaive with avg smape 29.82: \n",
            "Model Number: 87 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 210.6274\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 146.0603\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 137.3190\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 128.6016\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 130.1558\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 128.4335\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 123.9607\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.7866\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 124.8280\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.5327\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 114.2714\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 108.4445\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 119.6671\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.8509\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 109.0578\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.6302\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 113.2783\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.5405\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.0030\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 112.8481\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.3968\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.0976\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 104.9118\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 109.4358\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.2420\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.0613\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 113.8845\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.6314\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.4747\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.7065\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.3946\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.3881\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8020\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 105.6124\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.3243\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.6292\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.5523\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.7133\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 106.3119\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.4802\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.1359\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.7246\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.1977\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.4131\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 105.2267\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.6717\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 104.4131\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 104.1652\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.6279\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.2825\n",
            "87 - DatepartRegression with avg smape 30.43: \n",
            "Model Number: 88 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 13ms/step - loss: 119.5162\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 110.4028\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 111.4363\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.4813\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 109.1303\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.2245\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 108.7832\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.7418\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.4389\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.9612\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.0833\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.0042\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.6956\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.7873\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.3131\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.1716\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 107.3508\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 103.4005\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.2036\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.2125\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.4754\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 104.7570\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.9097\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 102.6857\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.8478\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 101.8886\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.2452\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.3626\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.2537\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 102.4867\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.9497\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.6969\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8091\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.6061\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.2357\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.1682\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.6367\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.0691\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.3233\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.9090\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.6236\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.5481\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.9024\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.2238\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.8908\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.9342\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.7467\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.6723\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.6006\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.9282\n",
            "88 - DatepartRegression with avg smape 30.33: \n",
            "Model Number: 89 of 155 with model MultivariateRegression for Validation 2\n",
            "89 - MultivariateRegression with avg smape 58.27: \n",
            "Model Number: 90 of 155 with model GLS for Validation 2\n",
            "90 - GLS with avg smape 29.79: \n",
            "Model Number: 91 of 155 with model WindowRegression for Validation 2\n",
            "91 - WindowRegression with avg smape 35.21: \n",
            "Model Number: 92 of 155 with model GLS for Validation 2\n",
            "92 - GLS with avg smape 29.76: \n",
            "Model Number: 93 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 16ms/step - loss: 126.5482\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 116.0379\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 112.2419\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.5346\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.9254\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 115.3213\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.8484\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 108.5440\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.9679\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 106.1077\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.4214\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 114.1548\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 109.6694\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.6028\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.8534\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.0291\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.9281\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.2162\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 105.2312\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.2824\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.8297\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.4022\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.8184\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.2588\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.9143\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.6107\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.9090\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 106.7332\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.6312\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.9698\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.5304\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 104.9067\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.0178\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.8549\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.4346\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.1611\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.9901\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.4913\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.9886\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.9379\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.4856\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.9178\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 106.7969\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7155\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.5442\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.7184\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.1848\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.0718\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.0247\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.7167\n",
            "93 - DatepartRegression with avg smape 30.75: \n",
            "Model Number: 94 of 155 with model SeasonalNaive for Validation 2\n",
            "94 - SeasonalNaive with avg smape 33.96: \n",
            "Model Number: 95 of 155 with model GLS for Validation 2\n",
            "95 - GLS with avg smape 30.82: \n",
            "Model Number: 96 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 123.7033\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 113.8295\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.2056\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 119.0042\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 110.2323\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 108.5962\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.2814\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.0123\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.6318\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.6402\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.4279\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 112.2758\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 105.0242\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 109.5760\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.9631\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.4422\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.2952\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.4476\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.9199\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.8224\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.2770\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.9331\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.0248\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.7409\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.6868\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.6857\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.4698\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.5726\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.1415\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8924\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.3394\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.7111\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.4658\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.8154\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.3686\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.2310\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.7903\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.0248\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7897\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 100.6458\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.9380\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.5094\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.7924\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.6664\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.0771\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.3296\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.3447\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.9580\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.4921\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.8766\n",
            "96 - DatepartRegression with avg smape 30.12: \n",
            "Model Number: 97 of 155 with model SeasonalNaive for Validation 2\n",
            "📈 97 - SeasonalNaive with avg smape 29.43: \n",
            "Model Number: 98 of 155 with model SeasonalNaive for Validation 2\n",
            "📈 98 - SeasonalNaive with avg smape 29.38: \n",
            "Model Number: 99 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 - ETS with avg smape 31.57: \n",
            "Model Number: 100 of 155 with model SeasonalNaive for Validation 2\n",
            "100 - SeasonalNaive with avg smape 30.82: \n",
            "Model Number: 101 of 155 with model ConstantNaive for Validation 2\n",
            "101 - ConstantNaive with avg smape 30.4: \n",
            "Model Number: 102 of 155 with model SeasonalNaive for Validation 2\n",
            "102 - SeasonalNaive with avg smape 31.12: \n",
            "Model Number: 103 of 155 with model DatepartRegression for Validation 2\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 408.1023\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 208.9836\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 257.8231\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 162.3528\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 189.2322\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 196.2311\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 172.8269\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 183.7789\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 163.5279\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 149.2890\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 142.6734\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 122.7879\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 141.9925\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 140.3828\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 118.3332\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 138.6393\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 130.6895\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 139.2341\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 135.3327\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 117.2302\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 121.8539\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 109.5777\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 111.7613\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 122.3753\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 125.1153\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 113.2267\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 115.8017\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 105.8120\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 120.8727\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 108.3626\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 115.7506\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.6092\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 117.4753\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 115.7370\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 114.0401\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 112.8926\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.3418\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 110.2008\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 110.7447\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 116.9728\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 113.1855\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.6067\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.7801\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 110.0300\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.2461\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 115.9385\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.0640\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.6214\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.2673\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.3110\n",
            "103 - DatepartRegression with avg smape 30.43: \n",
            "Model Number: 104 of 155 with model GLS for Validation 2\n",
            "104 - GLS with avg smape 32.22: \n",
            "Model Number: 105 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "105 - ETS with avg smape 38.03: \n",
            "Model Number: 106 of 155 with model GLS for Validation 2\n",
            "106 - GLS with avg smape 33.91: \n",
            "Model Number: 107 of 155 with model WindowRegression for Validation 2\n",
            "107 - WindowRegression with avg smape 35.02: \n",
            "Model Number: 108 of 155 with model SeasonalNaive for Validation 2\n",
            "108 - SeasonalNaive with avg smape 53.9: \n",
            "Model Number: 109 of 155 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109 - SeasonalNaive with avg smape 53.9: \n",
            "Model Number: 110 of 155 with model MultivariateRegression for Validation 2\n",
            "110 - MultivariateRegression with avg smape 37.42: \n",
            "Model Number: 111 of 155 with model SeasonalNaive for Validation 2\n",
            "111 - SeasonalNaive with avg smape 53.03: \n",
            "Model Number: 112 of 155 with model WindowRegression for Validation 2\n",
            "112 - WindowRegression with avg smape 42.0: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 2\n",
            "113 - NVAR with avg smape 34.34: \n",
            "Model Number: 114 of 155 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114 - SeasonalNaive with avg smape 30.05: \n",
            "Model Number: 115 of 155 with model WindowRegression for Validation 2\n",
            "115 - WindowRegression with avg smape 35.23: \n",
            "Model Number: 116 of 155 with model MultivariateRegression for Validation 2\n",
            "116 - MultivariateRegression with avg smape 80.69: \n",
            "Model Number: 117 of 155 with model NVAR for Validation 2\n",
            "117 - NVAR with avg smape 33.98: \n",
            "Model Number: 118 of 155 with model WindowRegression for Validation 2\n",
            "118 - WindowRegression with avg smape 33.57: \n",
            "Model Number: 119 of 155 with model ConstantNaive for Validation 2\n",
            "119 - ConstantNaive with avg smape 52.44: \n",
            "Model Number: 120 of 155 with model NVAR for Validation 2\n",
            "120 - NVAR with avg smape 32.7: \n",
            "Model Number: 121 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "121 - ETS with avg smape 31.81: \n",
            "Model Number: 122 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "122 - ETS with avg smape 31.12: \n",
            "Model Number: 123 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "123 - ETS with avg smape 30.99: \n",
            "Model Number: 124 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "124 - ETS with avg smape 31.03: \n",
            "Model Number: 125 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "125 - ETS with avg smape 31.01: \n",
            "Model Number: 126 of 155 with model ConstantNaive for Validation 2\n",
            "126 - ConstantNaive with avg smape 51.78: \n",
            "Model Number: 127 of 155 with model NVAR for Validation 2\n",
            "127 - NVAR with avg smape 33.03: \n",
            "Model Number: 128 of 155 with model ETS for Validation 2\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "128 - ETS with avg smape 36.85: \n",
            "Model Number: 129 of 155 with model NVAR for Validation 2\n",
            "129 - NVAR with avg smape 60.47: \n",
            "Model Number: 130 of 155 with model NVAR for Validation 2\n",
            "130 - NVAR with avg smape 33.61: \n",
            "Model Number: 131 of 155 with model MultivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - MultivariateRegression with avg smape 77.14: \n",
            "Model Number: 132 of 155 with model MultivariateRegression for Validation 2\n",
            "132 - MultivariateRegression with avg smape 138.8: \n",
            "Model Number: 133 of 155 with model UnivariateRegression for Validation 2\n",
            "133 - UnivariateRegression with avg smape 53.78: \n",
            "Model Number: 134 of 155 with model ConstantNaive for Validation 2\n",
            "134 - ConstantNaive with avg smape 53.78: \n",
            "Model Number: 135 of 155 with model ConstantNaive for Validation 2\n",
            "135 - ConstantNaive with avg smape 53.78: \n",
            "Model Number: 136 of 155 with model ConstantNaive for Validation 2\n",
            "136 - ConstantNaive with avg smape 53.78: \n",
            "Model Number: 137 of 155 with model ConstantNaive for Validation 2\n",
            "137 - ConstantNaive with avg smape 53.78: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 2\n",
            "138 - MultivariateRegression with avg smape 38.59: \n",
            "Model Number: 139 of 155 with model GLM for Validation 2\n",
            "139 - GLM with avg smape 49.63: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 2\n",
            "140 - MultivariateRegression with avg smape 52.67: \n",
            "Model Number: 141 of 155 with model UnobservedComponents for Validation 2\n",
            "141 - UnobservedComponents with avg smape 31.46: \n",
            "Model Number: 142 of 155 with model UnobservedComponents for Validation 2\n",
            "142 - UnobservedComponents with avg smape 31.47: \n",
            "Model Number: 143 of 155 with model UnobservedComponents for Validation 2\n",
            "143 - UnobservedComponents with avg smape 36.31: \n",
            "Model Number: 144 of 155 with model MultivariateRegression for Validation 2\n",
            "144 - MultivariateRegression with avg smape 55.39: \n",
            "Model Number: 145 of 155 with model UnobservedComponents for Validation 2\n",
            "145 - UnobservedComponents with avg smape 36.31: \n",
            "Model Number: 146 of 155 with model UnivariateRegression for Validation 2\n",
            "146 - UnivariateRegression with avg smape 55.26: \n",
            "Model Number: 147 of 155 with model UnivariateRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147 - UnivariateRegression with avg smape 56.13: \n",
            "Model Number: 148 of 155 with model UnivariateRegression for Validation 2\n",
            "148 - UnivariateRegression with avg smape 56.12: \n",
            "Model Number: 149 of 155 with model UnivariateRegression for Validation 2\n",
            "149 - UnivariateRegression with avg smape 50.67: \n",
            "Model Number: 150 of 155 with model UnivariateRegression for Validation 2\n",
            "150 - UnivariateRegression with avg smape 50.05: \n",
            "Model Number: 151 of 155 with model UnivariateRegression for Validation 2\n",
            "151 - UnivariateRegression with avg smape 53.53: \n",
            "Model Number: 152 of 155 with model GLM for Validation 2\n",
            "152 - GLM with avg smape 51.12: \n",
            "Model Number: 153 of 155 with model UnivariateRegression for Validation 2\n",
            "153 - UnivariateRegression with avg smape 69.4: \n",
            "Model Number: 154 of 155 with model GLM for Validation 2\n",
            "154 - GLM with avg smape 64.05: \n",
            "Model Number: 155 of 155 with model UnivariateRegression for Validation 2\n",
            "155 - UnivariateRegression with avg smape 170.24: \n",
            "Validation Round: 3\n",
            "Model Number: 1 of 155 with model Ensemble for Validation 3\n",
            "📈 1 - Ensemble with avg smape 24.1: \n",
            "Model Number: 2 of 155 with model Ensemble for Validation 3\n",
            "📈 2 - Ensemble with avg smape 23.64: \n",
            "Model Number: 3 of 155 with model Ensemble for Validation 3\n",
            "3 - Ensemble with avg smape 25.41: \n",
            "Model Number: 4 of 155 with model Ensemble for Validation 3\n",
            "4 - Ensemble with avg smape 25.8: \n",
            "Model Number: 5 of 155 with model Ensemble for Validation 3\n",
            "5 - Ensemble with avg smape 24.05: \n",
            "Model Number: 6 of 155 with model Ensemble for Validation 3\n",
            "6 - Ensemble with avg smape 25.91: \n",
            "Model Number: 7 of 155 with model Ensemble for Validation 3\n",
            "7 - Ensemble with avg smape 25.91: \n",
            "Model Number: 8 of 155 with model Ensemble for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 8 - Ensemble with avg smape 23.48: \n",
            "Model Number: 9 of 155 with model UnivariateMotif for Validation 3\n",
            "9 - UnivariateMotif with avg smape 26.24: \n",
            "Model Number: 10 of 155 with model UnivariateMotif for Validation 3\n",
            "10 - UnivariateMotif with avg smape 26.24: \n",
            "Model Number: 11 of 155 with model UnivariateMotif for Validation 3\n",
            "11 - UnivariateMotif with avg smape 24.1: \n",
            "Model Number: 12 of 155 with model UnivariateMotif for Validation 3\n",
            "12 - UnivariateMotif with avg smape 24.1: \n",
            "Model Number: 13 of 155 with model SectionalMotif for Validation 3\n",
            "📈 13 - SectionalMotif with avg smape 22.59: \n",
            "Model Number: 14 of 155 with model SectionalMotif for Validation 3\n",
            "📈 14 - SectionalMotif with avg smape 22.39: \n",
            "Model Number: 15 of 155 with model UnivariateMotif for Validation 3\n",
            "15 - UnivariateMotif with avg smape 27.04: \n",
            "Model Number: 16 of 155 with model SectionalMotif for Validation 3\n",
            "16 - SectionalMotif with avg smape 25.32: \n",
            "Model Number: 17 of 155 with model UnivariateMotif for Validation 3\n",
            "17 - UnivariateMotif with avg smape 23.54: \n",
            "Model Number: 18 of 155 with model SectionalMotif for Validation 3\n",
            "18 - SectionalMotif with avg smape 23.98: \n",
            "Model Number: 19 of 155 with model SectionalMotif for Validation 3\n",
            "19 - SectionalMotif with avg smape 23.95: \n",
            "Model Number: 20 of 155 with model SectionalMotif for Validation 3\n",
            "20 - SectionalMotif with avg smape 23.94: \n",
            "Model Number: 21 of 155 with model UnivariateMotif for Validation 3\n",
            "21 - UnivariateMotif with avg smape 22.77: \n",
            "Model Number: 22 of 155 with model SectionalMotif for Validation 3\n",
            "22 - SectionalMotif with avg smape 26.11: \n",
            "Model Number: 23 of 155 with model SectionalMotif for Validation 3\n",
            "23 - SectionalMotif with avg smape 26.12: \n",
            "Model Number: 24 of 155 with model SectionalMotif for Validation 3\n",
            "24 - SectionalMotif with avg smape 25.46: \n",
            "Model Number: 25 of 155 with model UnivariateMotif for Validation 3\n",
            "25 - UnivariateMotif with avg smape 25.48: \n",
            "Model Number: 26 of 155 with model UnivariateMotif for Validation 3\n",
            "26 - UnivariateMotif with avg smape 27.57: \n",
            "Model Number: 27 of 155 with model LastValueNaive for Validation 3\n",
            "27 - LastValueNaive with avg smape 38.87: \n",
            "Model Number: 28 of 155 with model LastValueNaive for Validation 3\n",
            "28 - LastValueNaive with avg smape 41.65: \n",
            "Model Number: 29 of 155 with model LastValueNaive for Validation 3\n",
            "29 - LastValueNaive with avg smape 41.7: \n",
            "Model Number: 30 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 - FBProphet with avg smape 23.98: \n",
            "Model Number: 31 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 - FBProphet with avg smape 24.64: \n",
            "Model Number: 32 of 155 with model FBProphet for Validation 3\n",
            "32 - FBProphet with avg smape 23.99: \n",
            "Model Number: 33 of 155 with model LastValueNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33 - LastValueNaive with avg smape 39.33: \n",
            "Model Number: 34 of 155 with model FBProphet for Validation 3\n",
            "34 - FBProphet with avg smape 24.85: \n",
            "Model Number: 35 of 155 with model MultivariateMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35 - MultivariateMotif with avg smape 28.89: \n",
            "Model Number: 36 of 155 with model FBProphet for Validation 3\n",
            "36 - FBProphet with avg smape 24.63: \n",
            "Model Number: 37 of 155 with model MultivariateMotif for Validation 3\n",
            "37 - MultivariateMotif with avg smape 26.46: \n",
            "Model Number: 38 of 155 with model MultivariateMotif for Validation 3\n",
            "38 - MultivariateMotif with avg smape 27.58: \n",
            "Model Number: 39 of 155 with model MultivariateMotif for Validation 3\n",
            "39 - MultivariateMotif with avg smape 27.58: \n",
            "Model Number: 40 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 - FBProphet with avg smape 24.96: \n",
            "Model Number: 41 of 155 with model LastValueNaive for Validation 3\n",
            "41 - LastValueNaive with avg smape 26.08: \n",
            "Model Number: 42 of 155 with model AverageValueNaive for Validation 3\n",
            "42 - AverageValueNaive with avg smape 24.07: \n",
            "Model Number: 43 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 - FBProphet with avg smape 22.89: \n",
            "Model Number: 44 of 155 with model FBProphet for Validation 3\n",
            "44 - FBProphet with avg smape 24.52: \n",
            "Model Number: 45 of 155 with model LastValueNaive for Validation 3\n",
            "45 - LastValueNaive with avg smape 26.13: \n",
            "Model Number: 46 of 155 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46 - FBProphet with avg smape 22.66: \n",
            "Model Number: 47 of 155 with model MultivariateMotif for Validation 3\n",
            "47 - MultivariateMotif with avg smape 26.99: \n",
            "Model Number: 48 of 155 with model MultivariateRegression for Validation 3\n",
            "48 - MultivariateRegression with avg smape 24.91: \n",
            "Model Number: 49 of 155 with model MultivariateMotif for Validation 3\n",
            "49 - MultivariateMotif with avg smape 25.98: \n",
            "Model Number: 50 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "38/38 [==============================] - 5s 5ms/step - loss: 644.9987\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 9.2497\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1710\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0231\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0207\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.0208\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0212\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0218\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0211\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0210\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0209\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0208\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0209\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.0211\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0213\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0212\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0214\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0216\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0217\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0222\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.0216\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0216\n",
            "50 - DatepartRegression with avg smape 27.35: \n",
            "Model Number: 51 of 155 with model MultivariateMotif for Validation 3\n",
            "51 - MultivariateMotif with avg smape 25.06: \n",
            "Model Number: 52 of 155 with model LastValueNaive for Validation 3\n",
            "52 - LastValueNaive with avg smape 28.72: \n",
            "Model Number: 53 of 155 with model LastValueNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 - LastValueNaive with avg smape 28.72: \n",
            "Model Number: 54 of 155 with model LastValueNaive for Validation 3\n",
            "54 - LastValueNaive with avg smape 28.71: \n",
            "Model Number: 55 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 14ms/step - loss: 156.4053\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.2465\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 134.8478\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 119.0997\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 120.7018\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 111.0386\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 125.9552\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 109.9408\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 121.4228\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 107.5899\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 109.3437\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 113.0402\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 115.8629\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 111.2548\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 110.7756\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.8505\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.0112\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 106.5174\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.9207\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 108.2282\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 104.5281\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.4589\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.5531\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8454\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 106.0592\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.3464\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.1860\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.7503\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.8281\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.8662\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.9610\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.6568\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.9138\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.7656\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.6122\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.1555\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 103.0343\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.2526\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.6247\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 100.8478\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 108.9301\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.0881\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.6676\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.8680\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.3199\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.4144\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 102.3276\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7299\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.3714\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.9312\n",
            "55 - DatepartRegression with avg smape 26.46: \n",
            "Model Number: 56 of 155 with model MultivariateMotif for Validation 3\n",
            "56 - MultivariateMotif with avg smape 30.65: \n",
            "Model Number: 57 of 155 with model MultivariateMotif for Validation 3\n",
            "57 - MultivariateMotif with avg smape 30.26: \n",
            "Model Number: 58 of 155 with model AverageValueNaive for Validation 3\n",
            "58 - AverageValueNaive with avg smape 26.18: \n",
            "Model Number: 59 of 155 with model AverageValueNaive for Validation 3\n",
            "59 - AverageValueNaive with avg smape 26.18: \n",
            "Model Number: 60 of 155 with model WindowRegression for Validation 3\n",
            "60 - WindowRegression with avg smape 26.67: \n",
            "Model Number: 61 of 155 with model AverageValueNaive for Validation 3\n",
            "61 - AverageValueNaive with avg smape 26.18: \n",
            "Model Number: 62 of 155 with model AverageValueNaive for Validation 3\n",
            "62 - AverageValueNaive with avg smape 26.18: \n",
            "Model Number: 63 of 155 with model GLS for Validation 3\n",
            "63 - GLS with avg smape 29.01: \n",
            "Model Number: 64 of 155 with model GLS for Validation 3\n",
            "64 - GLS with avg smape 25.06: \n",
            "Model Number: 65 of 155 with model AverageValueNaive for Validation 3\n",
            "65 - AverageValueNaive with avg smape 26.56: \n",
            "Model Number: 66 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 394.3642\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 219.9593\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 227.3472\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 233.6617\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 174.5894\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 174.3045\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 168.6498\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 155.3568\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 154.9434\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 186.1405\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 162.7627\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 149.3715\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 152.5615\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 138.4806\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 175.7442\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 132.0388\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 132.9698\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 134.7746\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 127.3862\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 130.1529\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 139.4424\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 133.5026\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 117.1227\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 124.9159\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 118.1728\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 123.8425\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 113.0547\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 114.9839\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 116.9932\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 125.2659\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 122.1511\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 115.6889\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 112.1727\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 119.8739\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 112.3175\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 117.2008\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 118.7082\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 108.5991\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 111.5859\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 115.3887\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 114.2562\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 112.5226\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 115.4955\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 109.2902\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 108.9861\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 106.4013\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 111.5305\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 114.5032\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 117.8883\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 110.5119\n",
            "66 - DatepartRegression with avg smape 25.29: \n",
            "Model Number: 67 of 155 with model AverageValueNaive for Validation 3\n",
            "67 - AverageValueNaive with avg smape 26.51: \n",
            "Model Number: 68 of 155 with model WindowRegression for Validation 3\n",
            "68 - WindowRegression with avg smape 26.57: \n",
            "Model Number: 69 of 155 with model WindowRegression for Validation 3\n",
            "69 - WindowRegression with avg smape 26.02: \n",
            "Model Number: 70 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "70 - ETS with avg smape 26.75: \n",
            "Model Number: 71 of 155 with model AverageValueNaive for Validation 3\n",
            "71 - AverageValueNaive with avg smape 25.81: \n",
            "Model Number: 72 of 155 with model AverageValueNaive for Validation 3\n",
            "72 - AverageValueNaive with avg smape 25.8: \n",
            "Model Number: 73 of 155 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 - UnobservedComponents with avg smape 25.51: \n",
            "Model Number: 74 of 155 with model GLS for Validation 3\n",
            "74 - GLS with avg smape 25.24: \n",
            "Model Number: 75 of 155 with model UnobservedComponents for Validation 3\n",
            "75 - UnobservedComponents with avg smape 25.55: \n",
            "Model Number: 76 of 155 with model UnobservedComponents for Validation 3\n",
            "76 - UnobservedComponents with avg smape 25.55: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 77 of 155 with model UnobservedComponents for Validation 3\n",
            "77 - UnobservedComponents with avg smape 25.73: \n",
            "Model Number: 78 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "38/38 [==============================] - 5s 5ms/step - loss: 645.2003\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 9.8179\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.8028\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6527\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6514\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6575\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6477\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6569\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6496\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6458\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6485\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6547\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6507\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6515\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6715\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6552\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6509\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6492\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6616\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6563\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6504\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6659\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6377\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6825\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6543\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6501\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6587\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6583\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6542\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6483\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6589\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6556\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6553\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6491\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6498\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6535\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6503\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.6528\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6612\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.6559\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6645\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6479\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6583\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6515\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6576\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.6669\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6693\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6721\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6756\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6623\n",
            "78 - DatepartRegression with avg smape 26.07: \n",
            "Model Number: 79 of 155 with model GLS for Validation 3\n",
            "79 - GLS with avg smape 25.04: \n",
            "Model Number: 80 of 155 with model UnobservedComponents for Validation 3\n",
            "80 - UnobservedComponents with avg smape 32.07: \n",
            "Model Number: 81 of 155 with model NVAR for Validation 3\n",
            "81 - NVAR with avg smape 50.04: \n",
            "Model Number: 82 of 155 with model NVAR for Validation 3\n",
            "82 - NVAR with avg smape 50.04: \n",
            "Model Number: 83 of 155 with model NVAR for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83 - NVAR with avg smape 38.22: \n",
            "Model Number: 84 of 155 with model ConstantNaive for Validation 3\n",
            "84 - ConstantNaive with avg smape 26.99: \n",
            "Model Number: 85 of 155 with model WindowRegression for Validation 3\n",
            "85 - WindowRegression with avg smape 26.07: \n",
            "Model Number: 86 of 155 with model ConstantNaive for Validation 3\n",
            "86 - ConstantNaive with avg smape 26.56: \n",
            "Model Number: 87 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 15ms/step - loss: 179.8913\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 131.7659\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 130.9426\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 130.3075\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 133.7763\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 122.8340\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 113.1976\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 111.3208\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.9227\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 109.0918\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 114.2058\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 107.0850\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.6620\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 105.4069\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 108.1461\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 106.9688\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.4026\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.5649\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.3776\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.9799\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.8219\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.7239\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.7137\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.8880\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8926\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 106.6805\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.8558\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 99.8804\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.7140\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 105.8507\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.7375\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.4916\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.2232\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.3009\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 99.9719\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.8306\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.2527\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 104.6650\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.3853\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.5412\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.5302\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.0549\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.1670\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.7779\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.6052\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 102.3182\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.4062\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7232\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.6265\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 99.3544\n",
            "87 - DatepartRegression with avg smape 25.82: \n",
            "Model Number: 88 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 16ms/step - loss: 113.5628\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 110.3254\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.2259\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.2911\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.9365\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.4091\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 106.5129\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 107.7685\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 104.4551\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.7063\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.4762\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.9559\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.0649\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.5353\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.8544\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 104.2219\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.9632\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 103.2271\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.7769\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.1798\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 99.6470\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.2538\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 99.9005\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.7262\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.2626\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.2904\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.1650\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.4318\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 101.7606\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.0644\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7491\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.7664\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 99.9863\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 99.8540\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.5850\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.0570\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.7899\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.7320\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.2171\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.1814\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.5659\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 99.6570\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.8157\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.0692\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.0905\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 99.6949\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 99.8155\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.1441\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.3966\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 100.2228\n",
            "88 - DatepartRegression with avg smape 27.15: \n",
            "Model Number: 89 of 155 with model MultivariateRegression for Validation 3\n",
            "89 - MultivariateRegression with avg smape 28.33: \n",
            "Model Number: 90 of 155 with model GLS for Validation 3\n",
            "90 - GLS with avg smape 26.5: \n",
            "Model Number: 91 of 155 with model WindowRegression for Validation 3\n",
            "91 - WindowRegression with avg smape 24.75: \n",
            "Model Number: 92 of 155 with model GLS for Validation 3\n",
            "92 - GLS with avg smape 26.47: \n",
            "Model Number: 93 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 6s 16ms/step - loss: 119.8475\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 107.7406\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8716\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 109.0360\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.2666\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 104.6872\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 105.2711\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 108.0429\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.2716\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.7562\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.9149\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.5777\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.9334\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.3992\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.7920\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.1482\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.8700\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.1451\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 102.0647\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 100.8981\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.6426\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 100.3045\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.1094\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 99.9608\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.0165\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8684\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 101.2489\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 100.5165\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 102.7751\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.2622\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.6371\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.9658\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7729\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.9064\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.0283\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.5267\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 101.8118\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.6684\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 100.4385\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.0298\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 102.7585\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 99.7783\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.3470\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.3013\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 99.7805\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.6732\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.9023\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 99.7628\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.0745\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 99.6748\n",
            "93 - DatepartRegression with avg smape 25.33: \n",
            "Model Number: 94 of 155 with model SeasonalNaive for Validation 3\n",
            "94 - SeasonalNaive with avg smape 28.09: \n",
            "Model Number: 95 of 155 with model GLS for Validation 3\n",
            "95 - GLS with avg smape 25.58: \n",
            "Model Number: 96 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 13ms/step - loss: 119.9436\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 115.4507\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.8289\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 107.1098\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 106.1987\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 109.9275\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.2381\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 111.0634\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 108.7835\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.7140\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 108.1529\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.6927\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 106.0627\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.5843\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 104.7026\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 103.7671\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.3310\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 107.2757\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 102.8504\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.4973\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 101.6723\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 104.5351\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.2420\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.4109\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 101.6815\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.9891\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 105.8146\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7523\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 100.6547\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 102.2874\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.9599\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 103.3636\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 100.3739\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 100.7561\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 103.2945\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 105.3963\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.7339\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 103.5079\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 101.6525\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 102.2129\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 105.0748\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 100.9768\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 101.8816\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 103.5648\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 100.4666\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 101.1831\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 104.1683\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 100.7388\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 101.0634\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 101.7510\n",
            "96 - DatepartRegression with avg smape 25.79: \n",
            "Model Number: 97 of 155 with model SeasonalNaive for Validation 3\n",
            "97 - SeasonalNaive with avg smape 28.27: \n",
            "Model Number: 98 of 155 with model SeasonalNaive for Validation 3\n",
            "98 - SeasonalNaive with avg smape 28.29: \n",
            "Model Number: 99 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 - ETS with avg smape 24.9: \n",
            "Model Number: 100 of 155 with model SeasonalNaive for Validation 3\n",
            "100 - SeasonalNaive with avg smape 35.95: \n",
            "Model Number: 101 of 155 with model ConstantNaive for Validation 3\n",
            "101 - ConstantNaive with avg smape 26.02: \n",
            "Model Number: 102 of 155 with model SeasonalNaive for Validation 3\n",
            "102 - SeasonalNaive with avg smape 27.75: \n",
            "Model Number: 103 of 155 with model DatepartRegression for Validation 3\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 7s 16ms/step - loss: 444.8051\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 433.3437\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 378.7034\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 280.3797\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 273.1117\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 287.7866\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 254.7546\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 248.9605\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 233.8457\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 184.7854\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 219.5921\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 208.5389\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 381.1018\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 206.7541\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 180.2977\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 176.5511\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 208.5063\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 201.8101\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 170.2674\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 154.6864\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 163.0728\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 232.3713\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 167.9875\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 140.1125\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 131.5774\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 183.2583\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 189.5312\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 175.8515\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 123.9485\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 174.5321\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 138.5192\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 155.2478\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 127.6218\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 151.5107\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 124.2827\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 134.5337\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 151.9448\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 148.5264\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 128.4896\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 120.5515\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 145.8343\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 123.5581\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 152.0725\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 119.5504\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 122.6247\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 131.9769\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 139.2602\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 113.8324\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 127.2310\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 140.3530\n",
            "103 - DatepartRegression with avg smape 25.44: \n",
            "Model Number: 104 of 155 with model GLS for Validation 3\n",
            "104 - GLS with avg smape 26.01: \n",
            "Model Number: 105 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "105 - ETS with avg smape 30.2: \n",
            "Model Number: 106 of 155 with model GLS for Validation 3\n",
            "106 - GLS with avg smape 23.59: \n",
            "Model Number: 107 of 155 with model WindowRegression for Validation 3\n",
            "107 - WindowRegression with avg smape 22.75: \n",
            "Model Number: 108 of 155 with model SeasonalNaive for Validation 3\n",
            "108 - SeasonalNaive with avg smape 24.04: \n",
            "Model Number: 109 of 155 with model SeasonalNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109 - SeasonalNaive with avg smape 24.04: \n",
            "Model Number: 110 of 155 with model MultivariateRegression for Validation 3\n",
            "110 - MultivariateRegression with avg smape 24.27: \n",
            "Model Number: 111 of 155 with model SeasonalNaive for Validation 3\n",
            "111 - SeasonalNaive with avg smape 25.33: \n",
            "Model Number: 112 of 155 with model WindowRegression for Validation 3\n",
            "📈 112 - WindowRegression with avg smape 20.54: \n",
            "Model Number: 113 of 155 with model NVAR for Validation 3\n",
            "113 - NVAR with avg smape 25.78: \n",
            "Model Number: 114 of 155 with model SeasonalNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114 - SeasonalNaive with avg smape 27.89: \n",
            "Model Number: 115 of 155 with model WindowRegression for Validation 3\n",
            "115 - WindowRegression with avg smape 21.7: \n",
            "Model Number: 116 of 155 with model MultivariateRegression for Validation 3\n",
            "116 - MultivariateRegression with avg smape 38.96: \n",
            "Model Number: 117 of 155 with model NVAR for Validation 3\n",
            "117 - NVAR with avg smape 25.4: \n",
            "Model Number: 118 of 155 with model WindowRegression for Validation 3\n",
            "118 - WindowRegression with avg smape 24.55: \n",
            "Model Number: 119 of 155 with model ConstantNaive for Validation 3\n",
            "119 - ConstantNaive with avg smape 24.89: \n",
            "Model Number: 120 of 155 with model NVAR for Validation 3\n",
            "120 - NVAR with avg smape 25.39: \n",
            "Model Number: 121 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "121 - ETS with avg smape 26.23: \n",
            "Model Number: 122 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "122 - ETS with avg smape 26.07: \n",
            "Model Number: 123 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "123 - ETS with avg smape 24.87: \n",
            "Model Number: 124 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "124 - ETS with avg smape 24.85: \n",
            "Model Number: 125 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "125 - ETS with avg smape 24.87: \n",
            "Model Number: 126 of 155 with model ConstantNaive for Validation 3\n",
            "126 - ConstantNaive with avg smape 24.13: \n",
            "Model Number: 127 of 155 with model NVAR for Validation 3\n",
            "127 - NVAR with avg smape 25.04: \n",
            "Model Number: 128 of 155 with model ETS for Validation 3\n",
            "ETS error TypeError(\"__init__() got an unexpected keyword argument 'damped_trend'\")\n",
            "128 - ETS with avg smape 24.2: \n",
            "Model Number: 129 of 155 with model NVAR for Validation 3\n",
            "129 - NVAR with avg smape 27.26: \n",
            "Model Number: 130 of 155 with model NVAR for Validation 3\n",
            "130 - NVAR with avg smape 24.68: \n",
            "Model Number: 131 of 155 with model MultivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131 - MultivariateRegression with avg smape 60.51: \n",
            "Model Number: 132 of 155 with model MultivariateRegression for Validation 3\n",
            "132 - MultivariateRegression with avg smape 20.59: \n",
            "Model Number: 133 of 155 with model UnivariateRegression for Validation 3\n",
            "133 - UnivariateRegression with avg smape 23.71: \n",
            "Model Number: 134 of 155 with model ConstantNaive for Validation 3\n",
            "134 - ConstantNaive with avg smape 23.71: \n",
            "Model Number: 135 of 155 with model ConstantNaive for Validation 3\n",
            "135 - ConstantNaive with avg smape 23.71: \n",
            "Model Number: 136 of 155 with model ConstantNaive for Validation 3\n",
            "136 - ConstantNaive with avg smape 23.71: \n",
            "Model Number: 137 of 155 with model ConstantNaive for Validation 3\n",
            "137 - ConstantNaive with avg smape 23.71: \n",
            "Model Number: 138 of 155 with model MultivariateRegression for Validation 3\n",
            "138 - MultivariateRegression with avg smape 28.08: \n",
            "Model Number: 139 of 155 with model GLM for Validation 3\n",
            "139 - GLM with avg smape 48.2: \n",
            "Model Number: 140 of 155 with model MultivariateRegression for Validation 3\n",
            "140 - MultivariateRegression with avg smape 23.29: \n",
            "Model Number: 141 of 155 with model UnobservedComponents for Validation 3\n",
            "141 - UnobservedComponents with avg smape 33.48: \n",
            "Model Number: 142 of 155 with model UnobservedComponents for Validation 3\n",
            "142 - UnobservedComponents with avg smape 33.45: \n",
            "Model Number: 143 of 155 with model UnobservedComponents for Validation 3\n",
            "143 - UnobservedComponents with avg smape 29.81: \n",
            "Model Number: 144 of 155 with model MultivariateRegression for Validation 3\n",
            "144 - MultivariateRegression with avg smape 40.49: \n",
            "Model Number: 145 of 155 with model UnobservedComponents for Validation 3\n",
            "145 - UnobservedComponents with avg smape 29.81: \n",
            "Model Number: 146 of 155 with model UnivariateRegression for Validation 3\n",
            "146 - UnivariateRegression with avg smape 36.44: \n",
            "Model Number: 147 of 155 with model UnivariateRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:90: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/link.py:93: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(lin_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:132: RuntimeWarning: invalid value encountered in true_divide\n",
            "  return -2 * (y - y_pred) / self.unit_variance(y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/_loss/glm_distribution.py:323: RuntimeWarning: invalid value encountered in add\n",
            "  dev = 2 * (xlogy(y, y / y_pred) - y + y_pred)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_glm/glm.py:323: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147 - UnivariateRegression with avg smape 35.79: \n",
            "Model Number: 148 of 155 with model UnivariateRegression for Validation 3\n",
            "148 - UnivariateRegression with avg smape 35.8: \n",
            "Model Number: 149 of 155 with model UnivariateRegression for Validation 3\n",
            "149 - UnivariateRegression with avg smape 27.68: \n",
            "Model Number: 150 of 155 with model UnivariateRegression for Validation 3\n",
            "150 - UnivariateRegression with avg smape 27.78: \n",
            "Model Number: 151 of 155 with model UnivariateRegression for Validation 3\n",
            "151 - UnivariateRegression with avg smape 37.51: \n",
            "Model Number: 152 of 155 with model GLM for Validation 3\n",
            "152 - GLM with avg smape 36.93: \n",
            "Model Number: 153 of 155 with model UnivariateRegression for Validation 3\n",
            "153 - UnivariateRegression with avg smape 28.03: \n",
            "Model Number: 154 of 155 with model GLM for Validation 3\n",
            "154 - GLM with avg smape 51.52: \n",
            "Model Number: 155 of 155 with model UnivariateRegression for Validation 3\n",
            "155 - UnivariateRegression with avg smape 109.51: \n",
            "Initiated AutoTS object with best model: \n",
            "Ensemble\n",
            "{}\n",
            "{'model_name': 'BestN', 'model_count': 5, 'model_metric': 'best_score_unique', 'models': {'adca25bc73760ee0063593c5bafb310b': {'Model': 'UnivariateMotif', 'ModelParameters': '{\"window\": 28, \"point_method\": \"mean\", \"distance_metric\": \"euclidean\", \"k\": 5, \"max_windows\": 10000}', 'TransformationParameters': '{\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"bkfilter\"}, \"transformation_params\": {\"0\": {}}}'}, '4f39f3424e427413d93bdf70043a6b56': {'Model': 'SectionalMotif', 'ModelParameters': '{\"window\": 10, \"point_method\": \"mean\", \"distance_metric\": \"braycurtis\", \"include_differenced\": true, \"k\": 5, \"stride_size\": 1, \"regression_type\": null}', 'TransformationParameters': '{\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"QuantileTransformer\", \"2\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 218}, \"2\": {}}}'}, '51a8b053bbe400eb614b41e6f3bf7f61': {'Model': 'LastValueNaive', 'ModelParameters': '{}', 'TransformationParameters': '{\"fillna\": \"KNNImputer\", \"transformations\": {\"0\": \"QuantileTransformer\", \"1\": \"SeasonalDifference\", \"2\": \"RobustScaler\"}, \"transformation_params\": {\"0\": {\"output_distribution\": \"uniform\", \"n_quantiles\": 100}, \"1\": {\"lag_1\": 7, \"method\": \"Mean\"}, \"2\": {}}}'}, '60ff3c9cf38790c1f00e817d17ee1fe0': {'Model': 'FBProphet', 'ModelParameters': '{\"holiday\": false, \"regression_type\": null, \"growth\": \"linear\", \"n_changepoints\": 25, \"changepoint_prior_scale\": 30, \"seasonality_mode\": \"additive\", \"changepoint_range\": 0.8, \"seasonality_prior_scale\": 10.0, \"holidays_prior_scale\": 10.0}', 'TransformationParameters': '{\"fillna\": \"time\", \"transformations\": {\"0\": \"PowerTransformer\"}, \"transformation_params\": {\"0\": {}}}'}, '618bebbd2aeb2e65d1c2a3c7612bf3ce': {'Model': 'MultivariateMotif', 'ModelParameters': '{\"window\": 10, \"point_method\": \"median\", \"distance_metric\": \"mahalanobis\", \"k\": 3, \"max_windows\": 10000}', 'TransformationParameters': '{\"fillna\": \"ffill\", \"transformations\": {\"0\": \"bkfilter\", \"1\": \"PCA\", \"2\": \"Detrend\"}, \"transformation_params\": {\"0\": {}, \"1\": {\"whiten\": false}, \"2\": {\"model\": \"GLS\", \"phi\": 1, \"window\": null}}}'}}, 'point_method': 'midhinge', 'model_weights': {}}\n",
            "SMAPE: 17.359446440909064, 16.386924196447925, 30.797028150844504, 23.483182266865803\n",
            "MAE: 15.431656368799668, 19.86474015334644, 26.85468978872201, 25.89874164910057\n",
            "SPL: 0.1529001978527504, 0.22601575251838546, 0.3290228922656362, 0.21743815253482865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = mod.predict()\n",
        "\n",
        "forecast = prediction.forecast\n",
        "\n",
        "model_results = mod.results()\n",
        "\n",
        "validation = mod.results(\"validation\")"
      ],
      "metadata": {
        "id": "5ABmD9SQkYEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97def21-31a0-49e4-edb5-779488b451c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(forecast)"
      ],
      "metadata": {
        "id": "BAcNWtwEkg-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5307c8-dc48-473e-b564-0a401b9e6143"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            description\n",
            "2022-01-03   131.395344\n",
            "2022-01-04   150.861604\n",
            "2022-01-05   150.106313\n",
            "2022-01-06   147.444888\n",
            "2022-01-07   137.840698\n",
            "2022-01-08    94.760295\n",
            "2022-01-09    16.303346\n",
            "2022-01-10   148.382480\n",
            "2022-01-11   147.419383\n",
            "2022-01-12   150.742583\n",
            "2022-01-13   151.895153\n",
            "2022-01-14   149.069985\n",
            "2022-01-15    86.218972\n",
            "2022-01-16    17.415368\n",
            "2022-01-17   153.262302\n",
            "2022-01-18   159.577455\n",
            "2022-01-19   161.386525\n",
            "2022-01-20   150.676546\n",
            "2022-01-21   147.581152\n",
            "2022-01-22    85.019869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7SXiHxvKwsf",
        "outputId": "fcca7fe5-bdfb-42c3-dc66-a4b2a7717b51"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   ID               Model  \\\n",
            "0    006d670bb178038daa411be4dd42d9c9  DatepartRegression   \n",
            "1    0181278de69621582f7c03c262606646                 ETS   \n",
            "2    01b5131416d6f8e785376ae9865a43c6  DatepartRegression   \n",
            "3    0256dff8b92a6b86aad6fb6bd46a4362                 ETS   \n",
            "4    0275c19262b8f4f6dd4b05c5128a9e67      LastValueNaive   \n",
            "..                                ...                 ...   \n",
            "978  fef3b025928a631d356180a81c9933e7       ConstantNaive   \n",
            "979  ff36218e54bf50976a6173d48f07592d     UnivariateMotif   \n",
            "980  ff5b6f2972140826986a8606aae57e47      SectionalMotif   \n",
            "981  ff60f06f5561a901febca5e4fa1c2325                NVAR   \n",
            "982  ffba89a2e955c3e7582eb5480babfa25   AverageValueNaive   \n",
            "\n",
            "                                       ModelParameters  \\\n",
            "0    {\"regression_model\": {\"model\": \"KerasRNN\", \"mo...   \n",
            "1    {\"damped_trend\": false, \"trend\": null, \"season...   \n",
            "2    {\"regression_model\": {\"model\": \"KerasRNN\", \"mo...   \n",
            "3    {\"damped_trend\": false, \"trend\": null, \"season...   \n",
            "4                                                   {}   \n",
            "..                                                 ...   \n",
            "978                                    {\"constant\": 1}   \n",
            "979  {\"window\": 60, \"point_method\": \"median\", \"dist...   \n",
            "980  {\"window\": 10, \"point_method\": \"midhinge\", \"di...   \n",
            "981  {\"k\": 1, \"ridge_param\": 2e-07, \"warmup_pts\": 5...   \n",
            "982                   {\"method\": \"Mean\", \"window\": 98}   \n",
            "\n",
            "                              TransformationParameters  Ensemble  Runs  \\\n",
            "0    {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0     4   \n",
            "1    {\"fillna\": \"zero\", \"transformations\": {\"0\": \"M...         0     1   \n",
            "2    {\"fillna\": \"rolling_mean\", \"transformations\": ...         0     1   \n",
            "3    {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0     1   \n",
            "4    {\"fillna\": \"pad\", \"transformations\": {\"0\": \"Mi...         0     1   \n",
            "..                                                 ...       ...   ...   \n",
            "978  {\"fillna\": \"fake_date\", \"transformations\": {\"0...         0     1   \n",
            "979  {\"fillna\": \"median\", \"transformations\": {\"0\": ...         0     1   \n",
            "980  {\"fillna\": \"median\", \"transformations\": {\"0\": ...         0     1   \n",
            "981  {\"fillna\": \"akima\", \"transformations\": {\"0\": \"...         0     1   \n",
            "982  {\"fillna\": \"ffill\", \"transformations\": {\"0\": \"...         0     1   \n",
            "\n",
            "          smape        mae       rmse      made  ...  mle_weighted  \\\n",
            "0     23.630947  23.634833  34.142871  0.486651  ...     11.595317   \n",
            "1     33.911209  34.792222  41.419958  0.577323  ...     10.621817   \n",
            "2    108.875959  83.841615  92.909956  0.849459  ...     81.637525   \n",
            "3     33.172238  25.844056  30.418866  0.498314  ...      9.578967   \n",
            "4     29.031356  23.119749  29.074995  0.459721  ...      6.088955   \n",
            "..          ...        ...        ...       ...  ...           ...   \n",
            "978   46.495894  41.425000  53.711614  0.765179  ...     24.285351   \n",
            "979   27.217443  25.458919  31.719658  0.579635  ...      7.170081   \n",
            "980   53.015293  54.885330  69.623560  1.119342  ...     16.378319   \n",
            "981   24.301448  22.174041  29.652537  0.535637  ...      5.943167   \n",
            "982   43.601549  40.726742  54.728738  0.783192  ...     16.497236   \n",
            "\n",
            "     imle_weighted  spl_weighted  maxe_weighted  oda_weighted  mqae_weighted  \\\n",
            "0        14.763802      0.381691     131.048730        0.8125      15.435754   \n",
            "1        27.467446      0.372251      81.163975        0.5500      28.819746   \n",
            "2         6.449329      0.486731     145.202480        0.7000      74.628728   \n",
            "3        19.345694      0.371464      67.898919        0.5500      21.430396   \n",
            "4        19.956749      0.196848      80.196551        0.6000      17.220089   \n",
            "..             ...           ...            ...           ...            ...   \n",
            "978      20.386575      0.816947     105.000000        0.7000      31.823529   \n",
            "979      21.211891      0.225357      75.488264        0.5500      19.925925   \n",
            "980      42.253792      0.314164     139.789282        0.5000      40.289254   \n",
            "981      18.944396      0.405387      83.435330        0.7000      15.630511   \n",
            "982      27.470659      0.549053     117.732577        0.7000      28.372771   \n",
            "\n",
            "     containment_weighted  contour_weighted  TotalRuntimeSeconds      Score  \n",
            "0                    0.95              0.70                 18.0  28.103811  \n",
            "1                    1.00              0.75                  1.0  33.926847  \n",
            "2                    0.90              0.40                 17.0  76.660325  \n",
            "3                    0.80              0.75                  1.0  30.972145  \n",
            "4                    0.70              0.75                  1.0  24.917440  \n",
            "..                    ...               ...                  ...        ...  \n",
            "978                  0.00              0.60                  1.0  51.445688  \n",
            "979                  0.85              0.70                  1.0  25.894583  \n",
            "980                  0.60              0.40                  1.0  46.942388  \n",
            "981                  0.15              0.60                  1.0  28.460983  \n",
            "982                  0.35              0.60                  1.0  44.332026  \n",
            "\n",
            "[983 rows x 34 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 980  ff5b6f2972140826986a8606aae57e47      SectionalMotif\n",
        "# 980   53.015293  54.885330  69.623560  1.119342  ...     16.378319  \n",
        "# RMSE value of SectionalMotif comes out to be 69.6 \n",
        "# Accuracy of SectionalMotif = 69.6%  "
      ],
      "metadata": {
        "id": "8A4Zye9UHEjQ"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}